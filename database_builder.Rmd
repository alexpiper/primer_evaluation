---
title: "Metabarcoding primer evaluation"
subtitle: "Database assembly"
author: "Alexander Piper"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
# Knitr global setup - change eval to true to run code
library(knitr)
knitr::opts_chunk$set(echo = TRUE, eval=FALSE, message=FALSE,error=FALSE, fig.show = "hold", fig.keep = "all")
opts_chunk$set(dev = 'png')
```


# Load Packages 

```{r load packages}
#Set required packages
.cran_packages <- c("usethis",
                    "tidyverse",
                    "rentrez", 
                    "bold",
                    "insect",
                    "ape",
                    "RColorBrewer",
                    "seqinr",
                    "patchwork",
                    "ShortRead",
                    "patchwork",
                    "geiger",
                    "castor",
                    "phytools",
                    "scales")

.bioc_packages <- c("DECIPHER",
                    "ggtree",
                    "Biostrings")

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}

#Load all packages
sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

# Github packages
devtools::install_github("alexpiper/taxreturn")
library(taxreturn)

# SOurce internal functions
source("R/helper_functions.R")
source("R/themes.R")


## Get an NCBI api key for taxize queries
# use_entrez()

# After generating your key set it as ENTREZ_KEY in .Renviron.
# ENTREZ_KEY='1c0a0c4afa28448650a1450662a22c68f208'
#usethis::edit_r_environ()
```

## Download data for all insecta

```{r retrieve sequences, eval=FALSE, include=FALSE}
dir.create("reference/database_builder/insecta/genbank",  recursive = TRUE)
dir.create("reference/database_builder/insecta/bold",  recursive = TRUE)

## Fetch sequences from GenBank
genbank <- fetchSeqs("Insecta", database = "genbank", out.dir="reference/database_builder/insecta/genbank", downstream = "Order", quiet=FALSE, marker="COI OR COI OR COX1 OR COXI", output = "gb-binom", compress=TRUE, multithread=TRUE, force=TRUE)

## Fetch sequences from BOLD
bold <- fetchSeqs("Insecta", database="bold", out.dir="reference/database_builder/insecta/bold", downstream = "Family", quiet=FALSE, marker="COI-5P", output = "gb-binom", compress=TRUE, multithread=TRUE, force=TRUE)

## Fetch mitochondrial genomes from genbank
fetchSeqs("Insecta", database="genbank", out.dir="reference/database_builder/insecta/genbank", quiet=FALSE, marker="mitochondria", output = "gb-binom", compress=TRUE, multithread=TRUE, force=TRUE)

```

## Download data for Arachnida

```{r retrieve arachnid seqs, eval=FALSE, include=FALSE}
#Create directories
dir.create("reference/database_builder/arachnida/genbank",  recursive = TRUE)
dir.create("reference/database_builder/arachnida/bold", recursive = TRUE)

## Fetch sequences from GenBank 
fetchSeqs("Arachnida", database="genbank", out.dir="reference/database_builder/arachnida/genbank", downstream="Order", quiet=FALSE, output = "gb-binom", compress=TRUE, multithread=TRUE, force=TRUE)

## Fetch sequences from BOLD
fetchSeqs("Arachnida", database="bold", out.dir="reference/database_builder/arachnida/bold", downstream=TRUE, quiet=FALSE, downto="Order", marker="COI-5P", output = "gb-binom",compress=TRUE, multithread=TRUE, force=TRUE)

## Fetch mitochondrial genomes from genbank
fetchSeqs("Arachnida", database="genbank", out.dir="reference/database_builder/arachnida/genbank", quiet=FALSE, marker="mitochondria", output = "gb-binom", compress=TRUE, multithread=TRUE, force=TRUE)

```


# Merge sequences

```{r merge and clean}
#Merge Genbank sequences
list.files("reference/database_builder/insecta/genbank/", pattern = ".fa$|.fa.gz$", full.names = TRUE, recursive = TRUE) %>% 
  purrr::map(readDNAStringSet) %>%
  purrr::map(writeXStringSet, filepath="reference/database_builder/insecta/genbank/genbank_insecta_COI_COI_COX1_COXI_20200728.fa", append=TRUE, width=20000)

#Merge BOLD sequences
list.files("reference/database_builder/insecta/bold/", pattern = ".fa$|.fa.gz$", full.names = TRUE, recursive = TRUE) %>% 
  purrr::map(readDNAStringSet) %>%
  purrr::map(writeXStringSet, filepath="reference/database_builder/insecta/bold/bold_insecta_coi5p_20200728.fa", append=TRUE, width=20000)

#Merge Genbank sequences
list.files("reference/database_builder/arachnida/genbank/", pattern = ".fa$|.fa.gz$", full.names = TRUE, recursive = TRUE) %>% 
  purrr::map(readDNAStringSet) %>%
  purrr::map(writeXStringSet, filepath="reference/database_builder/arachnida/genbank/genbank_arachnida_COI_COI_COX1_COXI_20200728.fa", append=TRUE, width=20000)

#Merge BOLD sequences
list.files("reference/database_builder/arachnida/bold/", pattern = ".fa$|.fa.gz$", full.names = TRUE, recursive = TRUE) %>% 
  purrr::map(readDNAStringSet) %>%
  purrr::map(writeXStringSet, filepath="reference/database_builder/arachnida/bold/bold_arachnida_coi5p_20200728.fa", append=TRUE, width=20000)

#gzip merged files
mergedfiles <- c(
  "reference/database_builder/insecta/genbank/genbank_insecta_COI_COI_COX1_COXI_20200728.fa",
  "reference/database_builder/insecta/bold/bold_insecta_coi5p_20200728.fa",
  "reference/database_builder/arachnida/genbank/genbank_arachnida_COI_COI_COX1_COXI_20200728.fa",
  "reference/database_builder/arachnida/bold/bold_arachnida_coi5p_20200728.fa"
) 

#gzip all merged files
mergedfiles %>%
  purrr::map(R.utils::gzip)

#Remove seperate sequences
allfiles <- c(list.files("reference/database_builder/insecta", pattern = ".fa$|.fa.gz$", full.names = TRUE, recursive = TRUE),
  list.files("reference/database_builder/insecta", pattern = ".fa$|.fa.gz$", full.names = TRUE, recursive = TRUE))

file.remove(allfiles[!allfiles %in% (mergedfiles %>% paste0(., ".gz"))])

#Merge sequences
seqs <- mergedfiles %>% 
  purrr::map(readDNAStringSet) %>%
  purrr::map(writeXStringSet, filepath="reference/database_builder/01_mergedseqs.fa", append=TRUE, width=20000)
R.utils::gzip("01_reference/database_builder/mergedseqs.fa")

# Dereplicate duplicated accessions
seqs <- readDNAStringSet(filepath = "reference/database_builder/01_mergedseqs.fa.gz")
uniqSeqs <- seqs[!duplicated(str_remove(names(seqs), "\\|.*$")),]
writeXStringSet(uniqSeqs, "reference/database_builder/02_uniqSeqs.fa.gz", width=20000, compress=TRUE)

```

## Check which could not be mapped

```{r failed mapping}
mapped_ott <- fasta.index("reference/database_builder/03_resolved.fa.gz") %>%
  tidyr::separate(desc, into=c("acc", "tax_id", "tax_name"), sep="\\||;") %>%
  mutate(tax_id = tax_id %>% dplyr::na_if("NA"))
  
unmapped <- fasta.index("reference/database_builder/02_uniqSeqs.fa.gz") %>%
  tidyr::separate(desc, into=c("acc", "tax_id", "name"), sep="\\||;") %>%
  dplyr::select(acc, tax_id, name) %>%
  mutate(tax_id = tax_id %>% dplyr::na_if("NA")) %>%
  filter(!acc %in% mapped_ott$acc)

# Check the types that could nto be mapped
db <- taxreturn::get_ott_taxonomy(dir="ott3.2", filter_unplaced = FALSE)

unmapped$name %in% db$tax_name %>% table()

unmapped_summary <- unmapped %>% 
  dplyr::rename(tax_name = name) %>%
  left_join(db) %>%
  mutate(type = case_when(
    str_detect(flags, "incertae_sedis") ~ "incertae_sedis",
    str_detect(flags, "major_rank_conflict") ~ "major_rank_conflict",
    str_detect(flags, "unplaced") ~ "unplaced",
    str_detect(flags, "environmental") ~ "environmental",    
    str_detect(flags, "infraspecific") ~ "infraspecific",    
    str_detect(flags, "inconsistent") ~ "inconsistent",    
    str_detect(flags, "extinct") ~ "extinct",    
    str_detect(flags, "hidden") ~ "hidden",        
    str_detect(flags, "hybrid") ~ "hybrid",      
    str_detect(flags, "not_otu") ~ "not_otu",    
    str_detect(flags, "viral") ~ "viral",      
    str_detect(flags, "barren") ~ "barren",
    str_detect(flags, "sibling_higher") ~ "sibling_higher",
    is.na(flags) ~ "not_present",
    TRUE ~ "other"
  ))

gg.unmapped <- unmapped_summary %>%
  group_by(type) %>%
  summarise(n = n()) %>%
  ggplot(aes(x = type, y=n, fill=type)) + 
  geom_col()+
  geom_text(aes(label = n, y = n), vjust=-0.2)+
  base_theme +
  scale_fill_brewer(palette = "Paired") +
  scale_y_log10(labels=scales::label_number_si()) +
  labs(
    x = "Type of unmapped sequence",
    y = "Number of sequences"
  ) 

gg.unmapped

pdf(file="fig/supplementary/taxon_flags_removed.pdf", width = 8, height = 6 , paper="a4r")
  plot(gg.unmapped)
try(dev.off(), silent=TRUE)
```


# Compare taxonomy mapping 

```{r compare taxonomy mapping}
#OTT Taxonomy
# Download ott taxonomy and make a database
taxreturn::download_ott_taxonomy(dest.dir="ott3.2", force=TRUE)
db <- taxreturn::get_ott_taxonomy(dir="ott3.2", filter_unplaced = FALSE)

## Map to Open tree of life taxonomy and resolve synonyms
uniqSeqs <- Biostrings::readDNAStringSet("reference/database_builder/02_uniqSeqs.fa.gz")
resolved <- map_to_ott(uniqSeqs, db, resolve_synonyms=TRUE, dir="ott3.2", filter_unplaced=TRUE, remove_na = TRUE, quiet=FALSE)

#filter unplaced taxa ie "incertae_sedis,|incertae_sedis$|major_rank_conflict|unplaced|environmental|inconsistent|extinct|hidden|hybrid|not_otu|viral|barren"
resolved <- filter_unplaced(resolved, db)

#filter infraspecific taxa
resolved <- filter_infraspecifc(resolved, db)

insect::writeFASTA(resolved, file="reference/database_builder/03_resolved.fa.gz", compress=TRUE)

# Filter any further sequences with problem names
resolved <- insect::readFASTA("reference/database_builder/03_resolved.fa.gz")
names <- names(resolved) %>%
  str_split_fixed(";", n=2) %>%
  as_tibble() %>%
  magrittr::set_colnames(c("acc", "name"))
rem <- names %>%
  dplyr::filter(str_detect(name,                        "sp\\.|spp\\.|aff\\.|nr\\.|bv\\.|cf\\.|nom\\.|nud\\.|environment|undescribed|unverified|unclassified|uncultured|unidentif|[0-9]|[:punct:]")) %>%
  pull(acc)
name_filtered  <- subset.DNAbin(resolved, subset = !str_replace(names(resolved), "(?:.(?!;))+$", "") %in% rem)
insect::writeFASTA(name_filtered, file="reference/database_builder/04_name_filtered.fa.gz", compress=TRUE)


#CHeck NCBI taxonomy
#Compare numbers of unique taxa and unique sequences that could be mapped to NCBI vs OTT taxonomy
#with remove_na=TRUE resolved wont contain any non-mapped
# While the taxid for all the rest should be NCBI or na?

uniqSeqs <- insect::readFASTA("reference/database_builder/02_uniqSeqs.fa.gz")
resolved_ncbi <- resolve_synonyms_ncbi(uniqSeqs, dir="ncbi_taxdump")

# need to resolve synonyms and remove infraspecifics for a fair comaprison here for a fair comparison

mapped_ncbi <- names(resolved_ncbi) %>%
  str_split_fixed(";", n=Inf) %>%
  as.data.frame() %>% 
  tidyr::separate(V1, into=c("acc", "taxid"), sep="\\|") %>%
  mutate(taxid = taxid %>% dplyr::na_if("NA")) %>%
  dplyr::rename(name = V2) %>%
  mutate(db = "ncbi")

mapped_ott <- fasta.index("reference/database_builder/03_resolved.fa.gz") %>%
tidyr::separate(desc, into=c("acc", "taxid", "name"), sep="\\||;") %>%
  dplyr::select(acc, taxid, name) %>%
  mutate(taxid = taxid %>% dplyr::na_if("NA")) %>%
  mutate(db = "ott")

mapping_comparison <- bind_rows(mapped_ncbi, mapped_ott) %>%
  dplyr::filter(!is.na(taxid)) %>%
  dplyr::filter(!str_detect(name,                        "sp\\.|spp\\.|aff\\.|nr\\.|bv\\.|cf\\.|nom\\.|nud\\.|environment|undescribed|unverified|unclassified|uncultured|unidentif|[0-9]|[:punct:]")) %>%
  group_by(db) %>%
  dplyr::summarise(unique_spp = n_distinct(taxid), unique_seqs = n()) 

gg.mapping_comparison <- mapping_comparison %>%
  pivot_longer(starts_with("unique"),
               names_to="type",
               values_to="value")  %>%
  mutate(type = type %>% 
           str_replace("unique_seqs", "Unique Sequences") %>%
           str_replace("unique_spp", "Unique Species")
           )%>%
    mutate(db = db %>% 
           str_replace("ncbi", "GenBank") %>%
           str_replace("ott", "OTT")
           )%>%
  ggplot(aes(x=db, y=value, fill=db)) + 
  geom_col() +
  geom_text(aes(label = value, y = value), vjust=-0.2)+
  base_theme +
  scale_fill_brewer(palette = "Paired") +
  facet_wrap(~type, scales="free_y") +
  labs(x = NULL,
       y = "Successfully mapped into taxonomy",
       fill="Reference Taxonomy") +
  scale_y_continuous(labels= scales::label_number_si())+
  theme(legend.position = "none",
        axis.text.x = element_blank())

gg.mapping_comparison


# Number of synonyms
ncbi_syns <- get_ncbi_synonyms(dir ="ncbi_taxdump")
ott_syns <- taxreturn::parse_ott_synonyms(dir = "ott3.2")
query <- names(uniqSeqs) %>%
  stringr::str_split_fixed(";", n = 2) %>% 
  tibble::as_tibble() %>% 
  tidyr::separate(col = V1, into = c("acc", "tax_id"), sep = "\\|") %>% 
            dplyr::rename(query = V2)

syn_comparison <- query %>%
  dplyr::select(-tax_id) %>%
  dplyr::mutate(
    ncbi_syn = case_when(
      query %in% ncbi_syns$synonym ~ TRUE,
      TRUE ~ FALSE),
    ott_syn = case_when(
      query %in% ott_syns$synonym ~ TRUE,
      TRUE ~ FALSE),
    ) %>%
  pivot_longer(contains("_syn"),
               names_to="db",
               values_to="syn")  %>%
  filter(syn == TRUE) %>%
  group_by(db) %>%
  dplyr::summarise(unique_spp = n_distinct(query), unique_seqs = n()) 

# Percentage of dataset
query %>%
  summarise(unique_spp = n_distinct(query), unique_seqs = n())
    
gg.syn_comparison <- syn_comparison %>%
  pivot_longer(starts_with("unique"),
               names_to="type",
               values_to="value")  %>%
  mutate(type = type %>% 
           str_replace("unique_seqs", "Unique Sequences") %>%
           str_replace("unique_spp", "Unique Species")
           )%>%
    mutate(db = db %>% 
           str_replace("ncbi_syn", "GenBank") %>%
           str_replace("ott_syn", "OTT")
           )%>%
  ggplot(aes(x=db, y=value, fill=db)) + 
  geom_col() +
  geom_text(aes(label = value, y = value), vjust=-0.2)+
  base_theme +
  scale_fill_brewer(palette = "Paired") +
  facet_wrap(~type, scales="free_y") +
  labs(x = NULL,
       y = "Synonyms resolved",
       fill="Reference Taxonomy") +
  scale_y_continuous(labels= scales::label_number_si())+
  theme(legend.position = "none")

gg.ref_comparison <- (gg.mapping_comparison + theme(legend.position = "none")) / gg.syn_comparison + plot_annotation(tag_levels = "A")

gg.ref_comparison
pdf(file="fig/supplementary/taxonomy_mapping_comparison.pdf", width = 10, height = 8 , paper="a4r")
  plot(gg.ref_comparison)
try(dev.off(), silent=TRUE)
```

## PHMM

### Build PHMM

```{r build PHMM}
#build PHMM from midori longest - sequences need to be same length
midori <-  Biostrings::readDNAStringSet("reference/MIDORI_LONGEST_20180221_COI.fasta")
insecta_midori <- as.DNAbin(midori[str_detect(names(midori),pattern=";Insecta;"),])
folmer <- insect::virtualPCR(insecta_midori, up = "TITCIACIAAYCAYAARGAYATTGG", down= "TAIACYTCIGGRTGICCRAARAAYCA",cores=2, rcdown = TRUE, trimprimers = FALSE)

#Filtered was then aligned in MAFFT and manually curated in geneious prime
folmer_curated <-  ape::read.dna("reference/folmer_insecta_fullength_aligned_curated.fa",format="fasta")
model <- aphid::derivePHMM(folmer_curated)
saveRDS(model, "reference/folmer_fullength_model.rds")
```


### Align to PHMM

```{r Align to phmm}
model <- readRDS("reference/folmer_fullength_model.rds")
seqs <- insect::readFASTA("reference/database_builder/04_name_filtered.fa.gz")

filtered <- taxreturn::map_to_model(seqs,  model, minscore = 100,
 shave=TRUE, check_indels=TRUE,  maxNs = 0,
 multithread=8, quiet=FALSE, progress = FALSE)

#Write out results filtered results
insect::writeFASTA(filtered, file="reference/database_builder/05_filtered.fa.gz",compress=TRUE)

```

## Remove stop codons

```{r stop codons}
filtered <- insect::readFASTA("reference/database_builder/05_filtered.fa.gz")

# Filter for stop codons
codonfilt <- taxreturn::codon_filter(filtered)

#Write out results filtered results
insect::writeFASTA(codonfilt, file="reference/database_builder/06_codon_filtered.fa.gz",compress=TRUE)
```

## Mixed clusters

```{r Mixed clusters}
codonfilt <- insect::readFASTA("reference/database_builder/06_codon_filtered.fa.gz")

# Remove duplicate accesions
seqs <- insect::subset.DNAbin(codonfilt, subset = !duplicated(str_extract(names(codonfilt), "^.*\\|" )))

# flag clusters with mixed taxonomy at different cluster thresholds and taxonomic ranks
db <- taxreturn::get_ott_taxonomy(dir="ott3.2")
set.seed(666)

mixed_clusters <- purrr::map_dfr(rev(seq(0.95, 1, 0.01)), ~taxreturn::get_mixed_clusters(
    x = seqs, db=db,
    rank = c("species","genus","family"),
    threshold = .x,
    return = "consensus",
    confidence=0.6, quiet = FALSE) 
)
write.csv(mixed_clusters,"mixedclusters.csv")

mixed_clusters <- vroom::vroom("reference/mixedclusters.csv")

gg.mixed <- mixed_clusters %>%
  group_by(threshold, rank) %>%
  summarise(n=n()) %>%
  ggplot(aes(x=as.factor(threshold), y=n, fill=rank, group=rank)) + 
  geom_bar(stat="identity", position="dodge", colour="black") +
  xlab("Clustering threshold") +
  ylab("Problem Sequences") +
  ggtitle("Mixed clusters") +
  theme_classic() +
  scale_fill_brewer(name = "Taxonomic Rank", palette="Greens") 

gg.mixed

# Purge all with mixed genus at 97, with confidence > 0.6  - >0.8 is probably better - Could i justify this with a probability of lowest common anestor?
rem <- mixed_clusters %>% 
  mutate(rem = case_when(
    rank=="species" & threshold >=0.99 & confidence > 0.8 ~ TRUE,
    rank=="genus" & threshold >=0.97 & confidence > 0.8 ~ TRUE,
    rank=="family" & threshold >=0.95 & confidence > 0.8 ~ TRUE,
    TRUE  ~ FALSE
    ))%>%
  filter(rem==TRUE) %>%
  pull(Acc) %>%
  unique()

length(rem)

purged  <- subset.DNAbin(seqs, subset = !str_replace(names(seqs), "(?:.(?!;))+$", "") %in% rem)
insect::writeFASTA(purged, file="reference/database_builder/07_purged.fa.gz", compress=TRUE)
```

## Remove contaminants

### Make contaminants database
```{r fetch wolbachia}
dir.create("reference/contaminants")
# Get wolbachia
fetchSeqs("wolbachia", database="genbank", out.dir="reference/contaminants", quiet=FALSE, marker="COI OR COI OR COX1 OR COXI", output = "standard", compress=FALSE, force=TRUE, multithread=FALSE)

# Get pseudogenes
fetchSeqs("Insecta", database="genbank", out.dir="reference/contaminants", downstream=FALSE, marker="COI[GENE] AND pseudo OR numt ", output = "standard", compress=TRUE, force=TRUE, multithread =FALSE)

# Exclude those without pseudo in name 
pseudo <- insect::readFASTA("reference/contaminants/Insecta_COI_AND_pseudo_numt_.fa.gz", compress=TRUE)
pseudo <- pseudo[str_detect(names(pseudo), "pseudo|numt")]
insect::writeFASTA(pseudo, "reference/contaminants/Insecta_COI_AND_pseudo_numt_filtered.fa.gz", compress=TRUE)

# Fetch human mitochondria from genbank
 searchQ <- paste("(", x, "[ORGN])", " AND (", 
                paste(c(marker), collapse = " OR "), ") AND ", 
                minlength, ":", maxlength, "[Sequence Length]", 
                sep = "")
ids <- rentrez::entrez_search(db = "nuccore", term = "NC_012920", retmax = 9999999, use_history = TRUE)$ids
dl <- rentrez::entrez_fetch(db = "nuccore", id = ids, rettype = "gb", retmax = 10000)
gb <- biofiles::gbRecord(rcd = textConnection(dl))

human_mito <- biofiles::getSequence(gb)
names(human_mito) <- paste0(biofiles::getAccession(gb), " ", biofiles::getDefinition(gb))
writeXStringSet(human_mito,"reference/contaminants/human_mito.fa")
```

### BLAST against Contaminants
```{r Contaminant BLAST}
# Blast against wolbachia
taxreturn::blast_install(dest.dir = "bin")

seqs <- insect::readFASTA("reference/database_builder/07_purged.fa.gz")

matchlist_wolb <- taxreturn::blast(query=seqs, db="reference/contaminants/wolbachia_COI_COI_COX1_COXI.fa.gz", output_format = "tabular", multithread = FALSE, args="-perc_identity 80 -max_target_seqs 10 -max_hsps 10") %>%
  as.data.frame()
write_csv(matchlist_wolb, "reference/contaminants/matchlist_wolb.csv")

matchlist_pseudo <- taxreturn::blast(query=seqs, db="reference/contaminants/Insecta_COI_AND_pseudo_numt_filtered.fa", output_format = "tabular", args="-perc_identity 97 -max_target_seqs 10 -max_hsps 10", multithread = FALSE) %>%
  as.data.frame()
write_csv(matchlist_pseudo, "reference/contaminants/matchlist_pseudo.csv")

matchlist_human <- taxreturn::blast(query=seqs, db="reference/contaminants/human_mito.fa", output_format = "tabular", args="-perc_identity 97 -max_target_seqs 10 -max_hsps 10", multithread = FALSE) %>%
  as.data.frame()
write_csv(matchlist_human, "reference/contaminants/matchlist_human.csv")

#blastn -db reference/contaminants/Insecta_COI_AND_pseudo_numt_filtered.fa -query reference/blast_query.fa  -outfmt "6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore qcovs qcovhsp" -evalue 1e-06 -num_threads 8 -perc_identity 97 -max_target_seqs 10 -max_hsps 10 -out matchlist_pseudo.csv

#blastn -db reference/contaminants/human_mito.fa -query reference/blast_query.fa  -outfmt "6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore qcovs qcovhsp" -evalue 1e-06 -num_threads 8 -perc_identity 97 -max_target_seqs 10 -max_hsps 10 -out matchlist_human.csv

# flag clusters with mixed taxonomy at different cluster thresholds and taxonomic ranks
matchlist_wolb <- vroom::vroom("reference/contaminants/matchlist_wolb.csv", delim=",") %>% 
dplyr::select(-name)
matchlist_pseudo <- vroom::vroom("reference/contaminants/matchlist_pseudo.csv", delim="\t", col_names=colnames(matchlist_wolb) )
matchlist_human <- vroom::vroom("reference/contaminants/matchlist_human.csv", delim="\t", col_names=colnames(matchlist_wolb) )

#Remove sequences that match wolbachia
rem_wolb <- matchlist_wolb %>%
  dplyr::filter(qcovs >= 80, pident >= 80) %>%
  mutate(acc =str_remove(qseqid, "(?:.(?!\\|))+$") ) %>%
  pull(acc)%>%
  unique()

rem_pseudo <- matchlist_pseudo %>%
  dplyr::filter(qcovs >= 99, pident >= 99) %>%
  mutate(acc =str_remove(qseqid, "(?:.(?!\\|))+$") ) %>%
  pull(acc) %>%
  unique()

rem_human <- matchlist_human %>%
  dplyr::filter(qcovs >= 97, pident >= 97) %>%
  mutate(acc =str_remove(qseqid, "(?:.(?!\\|))+$") ) %>%
  pull(acc) %>%
  unique()

rem_bads <- readLines("reference/contaminants/bad_accessions.txt")


rem <- unique(c(rem_wolb, rem_pseudo, rem_human, rem_bads))

table(str_remove(names(seqs), "(?:.(?!\\|))+$") %in% rem)

contam_purged  <- subset.DNAbin(seqs, subset = !str_remove(names(seqs), "(?:.(?!\\|))+$") %in% rem)

length(seqs) - length(contam_purged)
insect::writeFASTA(contam_purged, file="reference/database_builder/08_contam_removed.fa.gz", compress=TRUE)
```


## Filter length

```{r lengthfilt}
contam_purged <- readDNAStringSet("reference/database_builder/08_contam_removed.fa.gz")

maxgaps <- 712 - 300 #minlength 300 bases

rem <- names(contam_purged)[Biostrings::letterFrequency(contam_purged, "-") > maxgaps]
lengthfilt <- contam_purged[!names(contam_purged) %in% rem]

writeXStringSet(lengthfilt, "reference/database_builder/09_lengthfilt.fa.gz", compress=TRUE)
```

## Prune overrepresented groups
```{R prune}
# Prune large group sizes down to 5
set.seed(666)
lengthfilt <- insect::readFASTA("reference/database_builder/09_lengthfilt.fa.gz")
pruned <- prune_groups(lengthfilt, maxGroupSize = 5, discardby="length", dedup=TRUE, quiet = FALSE)

# Reformat to full taxonomic heirarchy
db <- taxreturn::get_ott_taxonomy(dir="ott3.2")
pruned <- reformat_hierarchy(pruned, db, ranks=c("kingdom", "phylum", "class", "order", "family", "genus", "species"), quiet=FALSE)

# Drop sequences with NA taxonomy
rem <- names(pruned)[str_detect(names(pruned), ";NA;")]
subset <- pruned[!names(pruned) %in% rem]
message(paste0(length(pruned) - length(subset), " Sequences with NA's in taxonomy removed"))
pruned <- subset
insect::writeFASTA(pruned, file="reference/database_builder/10_pruned.fa.gz", compress=TRUE)
```


# Reformat and Merge in inhouse sequences

```{r reformat seqs}
# read in  inhouse sequences
seqs <- readDNAStringSet(list.files("reference/inhouse/", pattern = ".fa", full.names = TRUE))

# Compare mapping to ncbi vs OTT
db <- taxreturn::get_ott_taxonomy(dir="ott3.2", filter_unplaced = FALSE)

#Get names into same format and map to ott
names(seqs) <- names(seqs) %>%
   str_split_fixed(pattern="_", n=2) %>%
  as.data.frame() %>%
  mutate(tax_name = str_replace(V2, "_", " ")) %>%
  mutate(tax_name = case_when(
    tax_name %in% (anti_join(., db, by="tax_name") %>% pull(tax_name)) ~ tax_name %>% str_remove(pattern="(\\ )(.*?)(?=$)"),
    !tax_name %in% (anti_join(., db, by="tax_name") %>% pull(tax_name)) ~ tax_name
  )) %>%
  left_join(db %>% select(-source, -id) %>% distinct(), by="tax_name") %>% 
  filter(!duplicated(V1)) %>%
  mutate(name = paste0(V1,"|", tax_id,";", V2)) %>%
  mutate(name = str_replace(name, "_", " ")) %>%
  pull(name)

#Deal with those that had NA species because only genus was in taxonomy
  
names <- reformat_hierarchy(seqs, db, quiet=FALSE, ranks=c("phylum", "class", "order", "family", "genus", "species")) %>%
  names() %>%
  str_split_fixed(pattern=";", n=Inf) %>%
  as.data.frame()%>%
  mutate(V8 = na_if(V8, "NA"))

names$V8[is.na(names$V8)] <- names(seqs)[is.na(names$V8)]%>% str_remove(pattern="^.*;")

names(seqs) <- names %>% tidyr::unite(col="names",1:8, sep = ";") %>%
  pull(names)
  
#filt using phmm
model <- readRDS("reference/folmer_fullength_model.rds")

filtered <- taxreturn::map_to_model(seqs,  model, minscore = 100,
 shave=TRUE, check_indels=TRUE,  maxNs = 0,
 multithread=1, quiet=FALSE, progress = FALSE)

# Filter for stop codons
codonfilt <- taxreturn::codon_filter(filtered)

# Write out reformatted inhouse 
insect::writeFASTA(codonfilt, file="reference/inhouse/inhouse_heirarchial.fa", compress = TRUE)

#merge
inhouse <- insect::readFASTA("reference/inhouse/inhouse_heirarchial.fa")

mergedSeqs <- c((insect::readFASTA(file="reference/database_builder/10_pruned.fa.gz")), inhouse)

#Remove any non-insect or arachnid as well as duplciate accessions
mergedSeqs <- filter_by_tax(mergedSeqs, filtrank = "Class", filtvalue =c("Insecta","Arachnida"))
mergedSeqs <- mergedSeqs[!duplicated(str_remove(names(mergedSeqs), "\\|.*$"))]


insect::writeFASTA(mergedSeqs, file="reference/merged_final.fa.gz", compress = TRUE)
```

# Create reference set for BF1-BR1 subregion of COI

While trimming the reference database to just the subregion does not necessarily affect the results of IDTAXA, it does dramatically decrease the size and increase the speed of classification with it
```{r Create taxonomic classifier database}
mergedSeqs <- Biostrings::readDNAStringSet("reference/merged_final.fa.gz")

# cut down alignments to the BF1-BR1 subregion
amplicon <- Biostrings::subseq(mergedSeqs, start=371, end = 588)

maxgaps <- 9 # dont allow any more than 9 gaps
rem <- names(amplicon)[Biostrings::letterFrequency(amplicon, "-") > maxgaps]
amplicon <- amplicon[!names(amplicon) %in% rem]
message(paste0(length(rem), " Sequences with more than ", maxgaps, " gaps removed from alignment"))
  
insect::writeFASTA(amplicon, "reference/merged_final_bftrimmed.fa.gz", compress=TRUE)

#Add 'root' rank to match the IDTAXA
heirarchial <- amplicon
names(heirarchial) <- names(heirarchial) %>%
  str_remove(";$") %>% 
  str_split_fixed(";", n=8) %>%
  as.data.frame() %>%
  magrittr::set_colnames(c("acc","kingdom", "phylum", "class", "order", "family", "genus", "species")) %>%
  mutate(root = "Root") %>%
  tidyr::unite(name, c("acc", "root","kingdom", "phylum", "class", "order", "family", "genus", "species"), sep=";") %>%
  pull(name)

heirarchial <- del.gaps(heirarchial)
insect::writeFASTA(heirarchial, "reference/classifiers/insecta_hierarchial_bftrimmed.fa.gz", compress=TRUE)

#Format for DADA2 species classifier
rdp_species <- reformat_dada2_spp(amplicon, quiet=FALSE)
rdp_species <- del.gaps(rdp_species)
insect::writeFASTA(rdp_species, "reference/classifiers/insecta_binomial_bftrimmed.fa.gz", compress=TRUE)

# Train IDTAXA
trainingSet <- train_idtaxa(amplicon)
#Write out training set
saveRDS(trainingSet, file="reference/classifiers/idtaxa_bftrimmed.rds")

#Summarise database
taxreturn::tax2tree(heirarchial, output="treedf") %>%
  write_tsv("reference/classifiers/insecta_hierarchial_tree_summary.txt")

names(heirarchial) %>%
  str_split_fixed(";", n=Inf) %>%
  as.data.frame() %>%
  magrittr::set_colnames(c("acc","root", "kingdom", "phylum", "class", "order", "family", "genus", "species")) %>%
  tidyr::separate(col=acc, into=c("accession", "taxid")) %>%
  write_csv("reference/classifiers/insecta_hierarchial_alltaxa.csv")

names(heirarchial) %>%
  str_split_fixed(";", n=Inf) %>%
  as.data.frame() %>%
  magrittr::set_colnames(c("total","root", "kingdom", "phylum", "class", "order", "family", "genus", "species")) %>%
  dplyr::summarise_at(c("total","root", "kingdom", "phylum", "class", "order", "family", "genus", "species"), n_distinct)%>%
  write_csv("reference/classifiers/insecta_hierarchial_summary.csv")
```
