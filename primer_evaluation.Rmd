---
title: "Primer evaluation"
title: "Statistics"
author: "Alexander Piper"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Introduction


## Load packages
```{r setup}
#Set required packages
.cran_packages <- c("usethis",
                    "tidyverse",
                    "spider", 
                    "insect",
                    "ape",
                    "RColorBrewer",
                    "seqinr",
                    "patchwork",
                    "ShortRead",
                    "foreach",
                    "doParallel",
                    "TmCalculator",
                    "castor",
                    "furrr",
                    "UpSetR",
                    "DescTools")

.bioc_packages <- c("DECIPHER",
                    "ggtree",
                    "Biostrings")

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}

#Load all packages
sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

# Github packages
devtools::install_github("alexpiper/taxreturn")
devtools::install_github("krassowski/complex-upset")
library(complex-upset)
library(taxreturn)
library(PrimerMiner)

# SOurce internal functions
source("R/helper_functions.R")
source("R/themes.R")
```

# Assemble pest list

* EPPO global database https://gd.eppo.int/ - DONE
* US APHIS - https://www.aphis.usda.gov/aphis/home/ - DONE
* QBank - https://qbank.eppo.int/arthropods/organisms - DONE
* Global invasive species database - http://www.iucngisd.org/gisd/search.php - DONE
* Global register of introduced or invasive species http://www.griis.org/ - DONE
* VectorBase: https://www.vectorbase.org/organisms - DONE
* DAWR top 40 - http://www.agriculture.gov.au/pests-diseases-weeds/plant - DONE
* PHA National biosecurity status report -  http://www.planthealthaustralia.com.au/national-programs/national-plant-biosecurity-status-report/ - DONE
* Ashfaq & Herbert 2016 - DNA barcodes for bio-surveillance: regulated and economically important arthropod plant pests - DONE
* CABI - https://t.co/LGjlFoOazd - DONE
* http://www.europe-aliens.org - DONE

```{r Curate pest lists}
dat <- list.files("primer_evaluation/pestlist/", pattern = ".csv", full.names = TRUE) %>%
  purrr::set_names() %>%
  map_dfr(read_csv, .id = "Source", col_types = cols("Species" = col_character())) %>%
  mutate(Source = str_remove(basename(Source), pattern="\\.csv")) %>%
  mutate(Species = Species %>%  
           str_remove_all("Ã¿") %>% #Resolve weird characters
           iconv(from = 'UTF-8', to = 'ASCII//TRANSLIT')%>% 
           str_remove_all("\\?") %>%
           str_remove_all("\\((.*?)\\)") %>% # remove things between brackets ie: Hygromia (Hygromia) cinctella
           str_squish() # remove excess whitespace
         ) %>%
  filter(str_count(Species, " ") > 0 ) %>% #Remove non-binomial 
  separate(Species, into=c("Genus", "Species"), sep=" ", extra="merge") %>% # Fix duplicated genus names
  mutate(Species = str_remove(Species, pattern=Genus) %>% str_squish()) %>%
  unite(col=Species, Genus, Species, sep = " ") %>%
  unique()

# Map to OTT taxonomy ids
db <- taxreturn::get_ott_taxonomy(dir="ott3.2", filter_unplaced = FALSE)

dat_resolved <- dat %>% mutate(mapped =taxreturn::map_to_ott(Species, db, resolve_synonyms=TRUE,  dir="ott3.2", filter_unplaced=TRUE, remove_na = FALSE, quiet=FALSE) ) %>%
  mutate(Species = mapped %>% str_remove("^.*;"),
         taxid = mapped %>% str_remove(";.*$") %>% str_remove("^.*\\|") )%>%
  mutate(taxid = na_if(taxid, "NA")) %>%
  dplyr::filter(!is.na(taxid)) %>%
  rownames_to_column("rows") %>%
  mutate(mapped = mapped %>% str_remove("^NA") %>% paste0(rows, .)) %>%  #Add dummy accession number
  dplyr::select(-rows)

lineage <- get_ott_lineage(dat_resolved$mapped, db) %>%
  bind_cols(dat_resolved) %>% 
  dplyr::select(-mapped, -tax_name, -Species) %>% 
  rename_all(funs(str_to_sentence(.))) %>%
  filter(Class %in% c("Insecta", "Arachnida")) %>%
  drop_na()

#Write out final list of pests 
write_csv(lineage, "primer_evaluation/pestlist.csv")
```

## Seqs per pest taxa

```{R}
seqs <- readFASTA("reference/database_builder/09_lengthfilt.fa.gz")
pestlist <- read_csv("primer_evaluation/pestlist.csv") %>%
  filter(Class=="Insecta") %>%
  distinct()

taxa <- names(seqs)%>%
  enframe() %>%
  select(-name) %>%
  separate(value, into=c("acc", "species"), sep=";") %>%
  mutate(pest = case_when(
    species %in% pestlist$Species ~ TRUE,
    !species %in% pestlist$Species ~ FALSE
  ))

#Number of taxa per species
n_seqs <- taxa %>% 
  group_by(species, pest) %>%
  summarise(sum = n())

# Mean number of seqs per spp
t.test(n_seqs %>% filter(pest) %>% pull(sum), n_seqs %>% filter(!pest) %>% pull(sum)) %>%
  broom::tidy()

# How many taxa didnt have seqs
table(pestlist$Species %in% taxa$species)

```


## Figure 1

```{r Figure 1}
lineage <- read_csv("primer_evaluation/pestlist.csv") %>%
  distinct() %>%
  mutate(Source = Source %>% str_remove("export_")) %>%
  mutate(Source = case_when(
    Source == "griis" ~ "GRIIS",
    Source=="gisd" ~ "GISD",
    Source=="europealiens" ~ "DAISIE",
    Source=="eppo" ~ "EPPO",
    Source=="ashfaq" ~ "Ashfaq et al 2016",
    Source=="qbank" ~ "Q-Bank",
    Source=="cabi" ~ "CABI",
    Source=="pha" ~ "PHA",
    Source=="vectorbase" ~ "VectorBase",
    Source=="dawr40" ~ "DAWR Top 40"
  ))


library(ggupset)
gg.upset <- lineage %>%
  dplyr::select(Species, Source) %>%
  group_by(Species) %>%
  summarise(Source = list(Source)) %>%
  ggplot(aes(x=Source)) +
    geom_bar() +
    scale_x_upset(n_intersections = 25) +
    base_theme +
    theme(panel.grid = element_blank()) +
  labs(x = "Intersection between datasets", y="Intersection size")

gg.upset

# Total set size
gg.total <- lineage %>%
  mutate(Source = factor(Source, levels=rev(c("GRIIS", "DAISIE", "EPPO", "Ashfaq et al 2016", "Q-Bank", "CABI", "PHA", "VectorBase", "DAWR Top 40", "GISD")))) %>%
  mutate(label = case_when(
   Class == "Insecta" & Order %in% c("Diptera" ,"Coleoptera", "Hemiptera", "Hymenoptera", "Lepidoptera", "Orthoptera") ~ Order,
  Class == "Arachnida" ~ "Arachnida",
  Class == "Insecta" & !Order %in% c("Diptera" ,"Coleoptera", "Hemiptera", "Hymenoptera", "Lepidoptera", "Orthoptera") ~ "Other Insects"
  )) %>%
  ggplot(aes(x=Source, fill=label))+
  geom_bar() +
  scale_fill_brewer(palette="Paired") + 
  base_theme +
  labs(x=NULL, y="Total records", fill="Taxon") +
  coord_flip()+
  theme(legend.position = "bottom") +
  scale_y_reverse()
  
# PCA of reference database
#Use unifrac and phylogenetic tree?


pca_dat <- lineage %>%
  dplyr::select(Species, Source) %>%
  distinct() %>%
  mutate(value = 1) %>%
  pivot_wider(names_from = Source, values_from=value, values_fill=0) %>%
  column_to_rownames("Species")


database_pca <- prcomp(vegan::vegdist(t(pca_dat), method="jaccard" ), scale. = TRUE)

gg.database_pca <-database_pca %>%
  broom::augment() %>%
    ggplot(aes(.fittedPC1, .fittedPC2, colour=.rownames, fill=.rownames)) +
    geom_point(size = 4, alpha = 0.8, shape=21, colour="black") +
  ggrepel::geom_text_repel(aes(label = .rownames, colour=.rownames))+
    labs(x = paste0("Principal component 1 (",  percent(percent_variation[1]), ")"), 
         y = paste0("Principal component 2 (",  percent(percent_variation[2]),")")) +
  geom_vline(xintercept = 0)+
  geom_hline(yintercept = 0) +
  base_theme +
  scale_color_brewer(palette = "Paired") +
  scale_fill_brewer(palette = "Paired") 

# Assemble figure 1

Fig1a <- gg.database_pca / gg.total + plot_layout(heights = c(2,1))

Fig1b <- gg.upset / grid::textGrob('')+ plot_layout(heights = c(10,1))

Fig1 <- Fig1a - Fig1b +  plot_annotation(tag_levels = 'A') 

Fig1

#Save figure 1
pdf(file="fig/Fig1_pestlist_summary.pdf", width = 11, height = 8 , paper="a4r")
  plot(Fig1)
try(dev.off(), silent=TRUE)
  
# Summaries for article text

# Unique taxa
lineage %>% 
  #select(-Source, Acc) %>%
  summarise(Species = n_distinct(Species),
            Genus = n_distinct(Genus),
            Family = n_distinct(Family),
            Order = n_distinct(Order),
            )
# Sum of reference DB's
lineage %>% 
  group_by(Source) %>%
  summarise(Species = n_distinct(Species)) %>%
  arrange(Species)

# Proportion of sequences unique
lineage %>%
  add_count(Source, name = "DB_total") %>%
  group_by(Species) %>%
  add_tally(name = "n_occurances") %>%
  ungroup() %>%
  filter(n_occurances==1) %>%
  group_by(Source, DB_total)%>%
  summarise(n = n_distinct(Species)) %>%
  mutate(freq = n / DB_total)%>%
  arrange(freq)
```


# Figure 2 - Sequence summary

```{r sequence tracker}
# Create read origins 
origin <- bind_rows(
  #Genbank Insecta
  fasta.index(list.files("reference/insecta/genbank", pattern = ".fa", full.names = TRUE)) %>%
  mutate(origin = "GenBank") %>% #genbank_insecta
  select(origin, desc),
  #BOLD Insecta
  fasta.index(list.files("reference/insecta/bold", pattern = ".fa", full.names = TRUE)) %>%
  mutate(origin = "BOLD") %>% #bold_insecta
  select(origin, desc),
  #Genbank Arachnida
  fasta.index(list.files("reference/arachnida/genbank", pattern = ".fa", full.names = TRUE)) %>%
  mutate(origin = "GenBank") %>% #genbank_arachnida
  select(origin, desc),
  #BOLD Arachnida
  fasta.index(list.files("reference/arachnida/bold", pattern = ".fa", full.names = TRUE)) %>%
  mutate(origin = "BOLD") %>% #bold_arachnida
  select(origin, desc),
) %>%
    mutate(seqid = desc %>%
    str_remove(pattern="(\\|)(.*?)(?=$)") %>%
    str_replace_all(" ", "_") ) %>%
  distinct() %>%
  mutate(Duplicated = case_when(
    duplicated(seqid) & str_detect(origin, "bold") ~ TRUE,
    TRUE ~ FALSE
    )) %>%
  filter(!Duplicated) %>%   
  filter(!duplicated(seqid)) %>%
  select(-Duplicated, -desc)

## summarise number of sequences at each stage and their origins
tracker <- bind_rows(
                  taxreturn::summarise_fasta("reference/01_mergedseqs.fa.gz",
                                             label="01_merged",
                                             origin=origin),
                  taxreturn::summarise_fasta("reference/02_uniqSeqs.fa.gz",
                                             label="02_unique",
                                             origin=origin),
                  taxreturn::summarise_fasta("reference/03_resolved.fa.gz",
                                             label="03_resolved",
                                             origin=origin),
                  taxreturn::summarise_fasta("reference/04_name_filtered.fa.gz",
                                             label="04_name_filt",
                                             origin=origin),
                  taxreturn::summarise_fasta("reference/05_filtered.fa.gz",
                                             label="05_phmm_filt",
                                             origin=origin),
                  taxreturn::summarise_fasta("reference/06_codon_filtered.fa.gz",
                                             label="06_codon_filt",
                                             origin=origin),
                  taxreturn::summarise_fasta("reference/07_purged.fa.gz",
                                             label="07_mixed_clusters",
                                             origin=origin),
                  taxreturn::summarise_fasta("reference/08_contam_removed.fa.gz",
                                             label="08_contam_removed",
                                             origin=origin), 
                  taxreturn::summarise_fasta("reference/09_lengthfilt.fa.gz",
                                             label="09_lengthfilt",
                                             origin=origin), 
                  taxreturn::summarise_fasta("reference/10_pruned.fa.gz", 
                                             label="10_pruned",
                                             origin=origin)

) %>%
  pivot_longer(cols=starts_with("n"),
               names_to = "Type",
               values_to = "value"
               )
write_csv(tracker, "reference/sequence_tracker.csv")

tracker <- read_csv("reference/sequence_tracker.csv")
tracker %>% 
  group_by(Type, label) %>%
  summarise(value = sum(value))

gg.cleaning <- tracker %>%
  filter(!origin %in% c("genbank_arachnida/genbank_insecta", "bold_arachnida/bold_insecta/genbank_arachnida/genbank_insecta")) %>%
  mutate(Type = Type %>% 
           str_replace("nseqs", "# Sequences") %>%
            str_replace("nspecies", "# Species")) %>%
  ggplot(aes(x=label, y=value, group=origin, fill=origin)) +
  geom_col(alpha=0.8) +
  facet_wrap(~Type, nrow=2, ncol=1, scales = "free_y") +
  scale_fill_brewer(palette="Paired") +
  xlab("Filter stage") +
  ylab("# Sequences") +
  scale_y_continuous(labels = scales::comma) +
  base_theme + 
  theme(legend.position="top",
        panel.grid = element_blank()) +
  labs(x = "Filter stage",
       y = NULL,
       fill = "Sequence Origin")

gg.cleaning
# find differences between lenghtfilt and pruned - why does total species reduce? is it hte way its calculated or just those that couldnt be mapped to taxonomy?

# Pre and post pruning

pruning_summary <- Biostrings::fasta.index("reference/database_builder/09_lengthfilt.fa.gz") %>%
  bind_rows(Biostrings::fasta.index("reference/database_builder/10_pruned.fa.gz"))%>%
  mutate(species = desc %>% str_remove("^.*;")) %>%
  mutate(stage = case_when(
    str_detect(filepath, "lengthfilt") ~ "Unpruned",
    str_detect(filepath, "pruned") ~ "Pruned"
  )) %>%
  dplyr::select(species, stage) %>%
  group_by(species, stage) %>%
  summarise(n = n())

gg.pruning <- ggplot(pruning_summary, aes(x = stage, y=n, fill=stage)) +
  geom_boxplot(colour="black", alpha = 0.5) + 
  base_theme+
  scale_y_log10() +
  scale_fill_brewer(palette = "Paired") + 
  coord_flip()+
  labs(y = "# Sequences per species", x= NULL) +
  theme(panel.grid = element_blank()) 


# Summary of unique taxa
seqs <- insect::readFASTA("reference/merged_final.fa.gz")

# Summarise unique ranks
names(seqs) %>%
  str_split_fixed(";", n=Inf) %>%
  as.data.frame() %>%
  magrittr::set_colnames(c("total", "kingdom", "phylum", "class", "order", "family", "genus", "species")) %>%
  dplyr::summarise_at(c("total", "kingdom", "phylum", "class", "order", "family", "genus", "species"), n_distinct) 


# Plot phylogenetic tree
# get Lineage for tree
seqs <- insect::readFASTA("reference/merged_final.fa.gz")

seqs <- acc2hex(seqs)

lineage <- names(seqs) %>%
  str_split_fixed(pattern="\\|", n = 2) %>%
  as_tibble() %>%
  separate(V2, into=c("taxid","Kingdom", "Phylum", 
    "Class", "Order", "Family", "Genus", "Species"), sep=";") %>%
  dplyr::rename(acc = V1)%>%
  mutate(Species = Species %>% str_replace_all(" ", "_")) %>%
  dplyr::select(-Species)


# Arrange on tree
tree <- ape::read.tree("reference/trees/ultrametric_insecta_tree_order_constrained.nwk")

# Prune tree to genus
tips_to_keep <- tree$tip.label %>% 
  enframe() %>% 
  tidyr::separate(value, into=c("acc", "Species"), sep="\\|") %>%
  left_join(lineage, by="acc") %>%
  filter(!is.na(Genus)) %>%
  group_by(Genus) %>%
  dplyr::slice(1) %>%
  ungroup() %>%
  mutate(tips = paste0(acc,"|", Species))


#Prune tree to genus
genus_tree  <- castor::get_subtree_with_tips(tree,
                                          only_tips = tips_to_keep$tips,
                                          collapse_monofurcations=TRUE,
                                          force_keep_root=TRUE)$subtree

genus_tree$tip.label <- genus_tree$tip.label %>%
  str_remove("\\|.*$")%>%
  enframe() %>%
  mutate(acc = value)%>%
  left_join(lineage) %>%
  pull(Genus)

Ntips 	<- length(genus_tree$tip.label)
Nnodes 	<- genus_tree$Nnode
cat(sprintf("Tree has %d nodes, %d tips and %d edges\n",Nnodes,Ntips,nrow(genus_tree$edge)));

# create internal node labels
genus_tree$node.label <- NA
if(is.na(genus_tree$node.label)){
	cat(sprintf("Adding node labels to full tree..\n"))
	genus_tree$node.label = paste("node.", 1:Nnodes, sep = "") # don't use underscores, because some tree readers (e.g. rncl) interpret them as spaces
}

# replace zero-length edges
if(any(genus_tree$edge.length==0)){
  epsilon = 0.1*min(genus_tree$edge.length[genus_tree$edge.length>0])
	cat(sprintf("Note: Some edges have length zero, which may break some of the HSP routines. Replacing zero-lengths with a tiny positive length (%g)..\n",epsilon))
	genus_tree$edge.length[genus_tree$edge.length==0] = epsilon
}

pestlist <- read_csv("primer_evaluation/pestlist.csv") 


# Plot tree
p1 <- ggtree(genus_tree , ladderize=TRUE, aes(colour=values), layout = "circular") 
  
weights_p1 <- p1$data %>%
  left_join(pestlist %>% 
              group_by(Genus) %>%
              summarise(values = n_distinct(Species)) %>%
              dplyr::rename(label = Genus) )%>%
  mutate(values = values %>% replace_na(0))
              
tip_states <- weights_p1 %>%
  dplyr::filter(isTip) %>%
  pull(values)
names(tip_states) <- weights_p1 %>%
  dplyr::filter(isTip) %>%
  pull(label)

weights_p1$values[!weights_p1$isTip] <- castor::asr_independent_contrasts(tree=genus_tree,
                                                          tip_states=tip_states, check_input = FALSE)$ancestral_states

p2 <- p1 %<+% weights_p1 +
 scale_color_gradient(low="darkslateblue", high="firebrick",na.value = NA, limits = c(0,5), oob = scales::squish) +
 theme(legend.position = "none") + 
 scale_y_continuous(expand=c(0,0))+ 
 scale_x_discrete(expand=c(0,0)) 

### make a clade label list
tax_groups <- tips_to_keep %>%
 dplyr::rename(label = Genus) %>%
 select(label, Order) %>%
 filter(label %in% genus_tree$tip.label) %>%
 group_by(Order) 

group_name <- group_keys(tax_groups)  %>%
 mutate(group_name = Order %>% str_remove_all("\\[|\\]"))

cls <- tax_groups %>% 
 group_split() %>% 
 purrr::map(pull, label) %>%
 set_names(group_name$group_name) %>%
 purrr::map(function(x){
   query <- x
   labs <-  p2$data %>%
     dplyr::filter(label %in% query)
   quants <- labs  %>% 
     dplyr::filter(between(y, left=quantile(labs$y,  probs =0.1), right=quantile(labs$y,  probs =0.90)))
   
   if(length(quants$label) > 1){
     mrca_node <- get_mrca_of_set(genus_tree, quants$label)
   
     if(mrca_node > Ntips){
       subset_node <- mrca_node-Ntips
     } else{
       subset_node <- mrca_node
     }
     subset_tree <- get_subtree_at_node(genus_tree, subset_node)$subtree
     print(length(subset_tree$tip.label))
     
     # Only label the bigger ones
     if(length(subset_tree$tip.label) < 50){
       mrca_node <- NULL
     }
   } else{
     mrca_node <- NULL
   }
   
   return(mrca_node)
 })

#drop small nodes
cls <- cls[!sapply(cls, is.null)]

# colours 
colourCount = length(cls)
getPalette = colorRampPalette(brewer.pal(12, "Paired"))
colour.pal <- getPalette(colourCount)

p3 <- p2
for(l in 1:length(cls)){
 p3 <- p3 + geom_cladelabel(
   node=cls[[l]], label=names(cls[l]), 
   align=T, hjust='center', offset.text=.25, 
   barsize=1.5, color = colour.pal[[l]])
}

gg.phylo <- p3

Fig2a <- gg.cleaning / gg.pruning + plot_layout(heights= c(3,1))
Fig2 <- Fig2a - gg.phylo + plot_layout(widths = c(2,3), ncol = 2)+ 
  plot_annotation(tag_levels = 'A') 

Fig2

#Save figure 2
pdf(file="fig/Fig2_database_summary.pdf", width = 11, height = 8 , paper="a4r")
  plot(Fig2)
try(dev.off(), silent=TRUE)
  
```


# Primer statistics

```{r primer binding and constraints}
#alignment was then manually curated in geneious primer
model <- readRDS("reference/folmer_fullength_model.rds")

# Be worth validating how the score is calculated?
primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  select(name, strand, seq, citation, issues) %>%
  left_join(.$seq %>% purrr::map(get_binding_position, model, tryrc = TRUE, minscore=8) %>%
              bind_rows() %>%
              dplyr::rename(seq = primer), by="seq")%>%
  distinct()

primers <- primers %>%
  left_join(.$seq %>%
  purrr::map_df(get_primer_statistics, metrics="all", disambiguate=TRUE))

write_csv(primers, "primer_evaluation/primer_candidates.csv")

#Number of unique forward and reverse
primers %>% 
  dplyr::select(seq, strand) %>%
  distinct() %>%
  pull(strand) %>%
  table()

```

## Primer Presence in seqs

```{r check pres}
primerHits <- function(primer, fn, max.mismatch=0, with.indels=FALSE) {
      if(stringr::str_detect(primer, "I")) {
        message(paste0("Warning: Inosine (I) bases detected in primer ", primer," these will be converted to N!"))
        primer <- primer %>% str_replace_all("I", "N")
        }
    # Counts number of sequences in which the primer is found
    nhits <- vcountPattern(primer, sread(readFasta(fn)), max.mismatch=max.mismatch, fixed = FALSE, with.indels = with.indels)
    return(sum(nhits > 0))
}

primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  distinct()

target="reference/merged_final.fa.gz"

out <- vector("list", length=nrow(primers))
for (i in 1:nrow(primers)){
  
  if(primers$strand[i] == "F"){
    query <- primers$seq[i]
    
  } else  if(primers$strand[i] == "R"){
    query <- rc(primers$seq[i])
  }
  print(i)
  df <- tibble(
    name = primers$name[i],
    primer = query,
    strand = primers$strand[i],
    #Hamming distance (no indels in COI)
    #h0 = primerHits(query, target, max.mismatch=0, with.indels=FALSE),
    #h1 = primerHits(query, target, max.mismatch=1, with.indels=FALSE),
    h2 = primerHits(query, target, max.mismatch=2, with.indels=FALSE),
  )
  out[[i]] <- df
}

names(out) <- primers$seq
out <- bind_rows(out)
write_csv(out, "primer_evaluation/primer_presence.csv")

# Plotting
out <- read_csv("primer_evaluation/primer_presence.csv") %>% 
  pivot_longer(cols=starts_with(c("h", "l")),
               names_to = "measure",
               values_to = "seqs"
               ) %>%
  filter(measure=="h2") %>%
  mutate(name = factor(name)) %>%
  arrange(name)

gg.primerpresF <- out %>%
  left_join(primers) %>%
  filter(strand=="F") %>%
    mutate(name = fct_reorder(name, seqs, .desc = TRUE)) %>%
  ggplot(aes(x=name, y=seqs, fill=seqs)) + 
  geom_bar(stat="identity", position="dodge") +
  coord_flip() + 
  labs(x="Forward Primers", y=NULL)  +
  base_theme +
  scale_y_continuous(labels = scales::label_number_si())+
  scale_fill_gradient(low = "firebrick", high = "darkslateblue", 
                      na.value = "grey", oob = scales::squish) 

gg.primerpresR <- out  %>%
  left_join(primers) %>%
  filter(strand=="R") %>%
    mutate(name = fct_reorder(name, seqs, .desc = TRUE)) %>%
  ggplot(aes(x=name, y=seqs, fill=seqs)) + 
  geom_bar(stat="identity", position="dodge") +
  coord_flip() + 
  labs(x="Reverse Primers", y="# Sequences containing primers") +
  base_theme +
  scale_y_continuous(labels = scales::label_number_si()) +
  scale_fill_gradient(low = "firebrick", high = "darkslateblue", 
                      na.value = "grey", oob = scales::squish) 

gg.primerpres <- gg.primerpresF / gg.primerpresR

gg.primerpres

pdf(file="fig/supplementary/primerpres.pdf", width = 8, height = 11 , paper="a4")
  plot(gg.primerpres)
try(dev.off(), silent=TRUE)
  
```

# Overview of COI

## Entropy
```{r Entropy}
# Get whole alignment entropy
seqs <- insect::readFASTA("reference/merged_final.fa.gz")
seqs <- seqs[lengths(seqs)==712]

## Entropy by individual order
queryrank <- "order"

# Get unique querieranks
queries <- names(seqs)  %>% 
  str_split_fixed(";", n = 8) %>% 
  as_tibble() %>% 
  magrittr::set_colnames(c("acc", "kingdom", "phylum",
                           "class", "order", "family", 
                           "genus", "species")) %>%
  filter(class %in% c("Insecta", "Arachnida")) %>%
  pull(queryrank) %>%
  unique()

#Make lists to store everything
entlist <- vector("list", length=length(queries))
names(entlist) <- queries

for (i in 1:length(queries)){
  print(i)
  query <- queries[i]
 print(query)
 
 subset <- filter_by_tax(seqs, filtrank=queryrank, filtvalue=query)
  if (length(subset) > 0){
    nseqs <- length(subset)
    message(nseqs, " sequences for ", query)
    # Get entropies
    entlist[[i]] <- taxreturn::alignment_entropy(as.list(subset), maskgaps=1, countgaps=FALSE, 
                                        method="ML", unit="log", return_extra = TRUE)
  }
}

ent_out <- bind_rows(entlist, .id="names")
write_csv(ent_out, paste0("primer_evaluation/", queryrank,"_ent_out.csv"))

# Read in per order entropy
ent <- read_csv("primer_evaluation/order_ent_out.csv") %>% 
  filter(bases > 20) # Filter to only those above 20 seqs

#Set moving average function - Adjust smoothing (n=5?)
ma <- function(x, n=3){stats::filter(x, rep(1/n, n), sides=2)}

ent_smoothed <- ent %>%
  mutate(ent = ent %>% 
           na_if("") %>%
           replace_na(0)) %>%
  mutate(ma = ma(ent, n = 3)) %>%
  mutate(ma = ma %>% replace_na(0)) %>%
  mutate(annot = case_when(
    pos %in% seq(from=1, to=2, by=1) ~ "Loop 0",
    pos %in% seq(from=3, to=78, by=1) ~ "Helix 1",
    pos %in% seq(from=79, to=103, by=1)~ "Loop 1-2",
    pos %in% seq(from=104, to=211, by=1)~ "Helix 2",    
    pos %in% seq(from=212, to=235, by=1)~ "Loop 2-3",   
    pos %in% seq(from=213, to=304, by=1)~ "Helix 3", 
    pos %in% seq(from=305, to=373, by=1)~ "Loop 3-4", 
    pos %in% seq(from=374, to=466, by=1)~ "Helix 4", 
    pos %in% seq(from=467, to=499, by=1)~ "Loop 4-5", 
    pos %in% seq(from=500, to=598, by=1)~ "Helix 5", 
    pos %in% seq(from=599, to=634, by=1)~ "Loop 5-6", 
    pos %in% seq(from=635, to=712, by=1)~ "Helix 6", 
  )) %>%
  mutate(structure = case_when(
    str_detect(annot, "Helix") ~ "Helix",
    str_detect(annot, "Loop") ~ "Loop",
  ))  

## plot entropy by order
colourCount = length(unique(ent_smoothed$names))
getPalette = colorRampPalette(brewer.pal(9, "Paired"))

gg.separate_ent <- ent_smoothed %>%
  group_by(pos) %>%
  mutate(median = median(ma)) %>%
  ggplot(aes(x = pos, y=ma, colour=names)) + 
  geom_line(aes(x = pos, y=ma)) +
  facet_wrap(~names, ncol=3) +
  base_theme +
  labs(
    x="Position within COI barcode locus",
    y="Shannons Entropy (H)")  +
  scale_color_manual(values = getPalette(colourCount))+
  scale_x_continuous(limits = c(0, 712), expand=c(0,0))

gg.separate_ent
pdf(file="fig/supplementary/all_orders_entropy.pdf", width = 8, height = 11 , paper="a4")
  plot(gg.separate_ent)
try(dev.off(), silent=TRUE)


# Plot entropy of COI Gene
gg.entropy <- ent_smoothed %>%
  group_by(pos) %>%
  mutate(median = median(ma)) %>%
  ggplot(aes(x = pos, y=ma, group=pos, colour=structure)) + 
  geom_boxplot(outlier.shape = NA, alpha=0.8) +
  geom_line(aes(x = pos, y=median),size=1, inherit.aes = FALSE) + #, colour="black"
  theme_classic() +    
  theme(legend.position = "none",
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.title.x = element_blank()) +
  labs(
    x="Position within COI barcode locus",
    y="Shannons Entropy (H)",
    colour="3D structure") +
  scale_color_manual(values=c("#e31a1c","#1f78b4")) +
  scale_x_continuous(limits = c(0, 712), breaks=seq(0,700,50), expand=c(0,0)) 

# Plot number of sequence across whole gene
gg.sequences <- ent_smoothed %>%
  group_by(pos) %>%
  summarise(bases = sum(bases), structure) %>%
  ggplot(aes(x = pos, y=bases)) + 
  geom_line()+
  #geom_boxplot(outlier.shape = NA, alpha=0.8) +
  theme_classic() +    
  theme(legend.position = "none") +
  labs(
    x="Position within COI barcode locus",
    y="# Sequences", colour=NULL) +
  scale_x_continuous(limits = c(0, 712), breaks=seq(0,700,50), expand=c(0,0), labels=scales::unit_format(unit="bp")) +
  scale_y_continuous(labels = scales::label_number_si())+
  scale_color_manual(values=c("#e31a1c","#1f78b4"))  



## Primers
range_join <- function(x, y, value, range_start, range_stop){
  if(!any(stringr::str_detect(colnames(y), range_start)) | !any(stringr::str_detect(colnames(y), range_stop))){
    stop("Arguments range_start and range_stop must be valid columns in y")
  }
  splits <- split(y, 1:nrow(y))
  out <- tibble()
  for (i in 1:length(splits)){ 
    y_ <- splits[[i]]
    dat <- x[x[[value]] >= y_[[range_start]] & x[[value]] < y_[[range_stop]],]     
    if(nrow(dat) > 0)      
      out <-  out %>% bind_rows(dat %>% cbind(y_))  
  }
  return(out)
}

primers <- read_csv("primer_evaluation/primer_candidates.csv") %>% 
  distinct()

#Add ranks in overlapping windows to arrange y by
windowsize=130

primer_windows <- primers %>%
  range_join(
    enframe(seq(min(primers$start), max(primers$end + 100), by = windowsize)) %>%
    dplyr::rename(window= name, winend=value) %>%
    mutate(winstart = winend - windowsize), value="start", range_start="winstart", range_stop="winend") %>%
  group_by(window) %>%
  arrange(start) %>%
  mutate(rank=row_number()) %>%
  ungroup()

gg.primers <- ggplot(data=ent_smoothed[ent_smoothed$pos==1,], aes(x = as.numeric(pos))) +
  geom_segment(data = primer_windows %>% filter(strand=="F"),
               aes(x = start, xend = end,
                   y = rank, yend = rank,
                   colour=strand), size = 1, arrow = arrow(length = unit(0.3,"cm")),
               show.legend = FALSE) +
  geom_text(data = primer_windows %>% filter(strand=="F"),
            aes(x = start, y = rank,
                label = name , colour=strand),
            hjust = 1, show.legend = FALSE) +
  geom_segment(data = primer_windows %>% filter(strand=="R"),
               aes(x = end, xend = start,
                   y = rank, yend = rank,
                   colour=strand), size = 1,
               arrow = arrow(length = unit(0.3,"cm")),
               show.legend = FALSE) +
  geom_text(data = primer_windows %>% filter(strand=="R"),
            aes(x = end, y = rank,
                label = name, colour=strand),
            hjust = 0, show.legend = FALSE)  +
  scale_x_continuous(limits = c(0, 712), breaks=seq(0,700,50), expand=c(0,0)) +
  theme_void()+
    labs(x="Position within COI barcode locus", y=NULL, colour=NULL)  +
  scale_color_manual(values=c("#e31a1c","#1f78b4"))

gg.primers


```

# Sliding window

## Sliding window PCR
```{r}
# Load seqs
seqs <- readDNAStringSet("reference/merged_final.fa.gz")
seqs <- seqs[lengths(seqs)==712]
# Sliding window
alignment_sw <- function(x, width, interval = 1, maxgaps=0){
  alignment_width <- max(width(x))
  win <- seq(1,  alignment_width - width, by = interval) #Get all possible windows
  out <- vector("list", length=length(win))
  for(i in 1:length(win)){
    amplicon <- Biostrings::subseq(x, start=win[i], end = win[i]+width) #may need to add 1 to start
    rem <- names(amplicon)[Biostrings::letterFrequency(amplicon, "-") > maxgaps]
    amplicon <- amplicon[!names(amplicon) %in% rem]
    out[[i]] <- amplicon
  }
  names(out) <- paste(win, win+width, sep="-")
  return(out)
}

# Make 200bp windows
dir.create("primer_evaluation/amplicons/win200/")
alignment_sw(seqs, width=200, interval=3, maxgaps=9) %>%
  purrr::map2(., names(.), ~Biostrings::writeXStringSet(.x, file=paste0("primer_evaluation/amplicons/win200/", .y,".fa.gz"), compress=TRUE))

# Make 300bp windows
dir.create("primer_evaluation/amplicons/win300/")
alignment_sw(seqs, width=300, interval=3, maxgaps=9) %>%
  purrr::map2(., names(.), ~Biostrings::writeXStringSet(.x, file=paste0("primer_evaluation/amplicons/win300/", .y,".fa.gz"), compress=TRUE))

# Make 400bp windows
dir.create("primer_evaluation/amplicons/win400/")
alignment_sw(seqs, width=400, interval=3, maxgaps=9) %>%
  purrr::map2(., names(.), ~Biostrings::writeXStringSet(.x, file=paste0("primer_evaluation/amplicons/win400/", .y,".fa.gz"), compress=TRUE))

```
 
 
## USEARCH distance matrix

```{bash generate job index}
#!/bin/bash
dos2unix bash/usearch_distmat.sh
/usr/bin/ls -d /group/pathogens/Alexp/Metabarcoding/primer_evaluation/primer_evaluation/amplicons/win*/* | sed -e '1p' -e '/.fa.gz/!d' | sort -u > job_index.txt
njobs=$(cat job_index.txt | wc -l)
sbatch --array=1-$njobs bash/usearch_distmat.sh
```


# ID Success SW

```{r analyse uclust}
# Summarise number of mixed clusters that contain pests at %
pestlist <- read_csv("primer_evaluation/pestlist.csv") 

# Get mixed clusters
library(furrr)
plan(multiprocess, workers=8)
sw_clusters <- c(fs::dir_ls(path="primer_evaluation/amplicons/win200/usearch_output/", glob = "*.txt.gz"),
                    fs::dir_ls(path="primer_evaluation/amplicons/win300/usearch_output/", glob = "*.txt.gz"),
                    fs::dir_ls(path="primer_evaluation/amplicons/win400/usearch_output/", glob = "*.txt.gz")) %>%
  furrr::future_map(function(x){
  #purrr::map(function(x){
  vroom::vroom(x, delim="\t", col_names = c("acc1", "acc2", "dist")) %>%
    dplyr::mutate(spp1 = acc1 %>%
                    str_remove(";$") %>%
                    str_remove("^.*;"),
                  acc1 = acc1 %>% str_remove(";.*$"),
                  spp2 = acc2 %>%
                    str_remove(";$") %>%
                    str_remove("^.*;"),
                  acc2 = acc2 %>% str_remove(";.*$"),
                  dist = round(dist, 2)) %>%
    dplyr::filter(!spp1==spp2)%>%
        dplyr::group_by(dist) %>% 
        dplyr::summarise(mixed=n_distinct(spp1))
  })%>%
  bind_rows(.id="source") %>%
  mutate(source = str_remove(basename(source), ".txt.gz")) %>%
  mutate(win_start = source %>% str_remove("-.*$")  %>% as.numeric(),
         win_end = source %>% str_remove("^.*-") %>% as.numeric()) %>%
  mutate(win_length = win_end - win_start)
  
#Get amplified
amplified <-c(fs::dir_ls(path="primer_evaluation/amplicons/win200/", glob = "*.fa.gz"),
              fs::dir_ls(path="primer_evaluation/amplicons/win300/", glob = "*.fa.gz"),
              fs::dir_ls(path="primer_evaluation/amplicons/win400/", glob = "*.fa.gz")) %>%
   purrr::map(function(x){
   #furrr::future_map(function(x){
     fasta.index(x) %>%
        mutate(species = desc %>% 
                 str_remove("(?:[^;]*;){7}") %>% #match 7th ;
                 str_remove(";$"))  %>%
      dplyr::group_by(filepath) %>%
      dplyr::summarise(seqs_amplified = n(), spp_amplified = n_distinct(species)) 
   }) %>%
  bind_rows() %>%
  mutate(source = str_remove(basename(filepath), ".fa.gz")) %>%
  dplyr::select(-filepath)

sw_joint <- sw_clusters %>%
  left_join(amplified) 
vroom::vroom_write(sw_joint, "primer_evaluation/amplicons/sw_clusters_summary.csv", delim=",")

# Read in
sw_joint <- vroom::vroom("primer_evaluation/amplicons/sw_clusters_summary.csv", delim=",")%>%
  mutate(pos = win_start) %>%
  mutate(success =  (spp_amplified - mixed)/spp_amplified,
           threshold = 1-dist)

# New plot
sw_means <- sw_joint %>%
  filter(win_start > 25, win_end < (712-26)) %>%
  group_by(source, threshold) %>%
  group_split() %>%
  purrr::map(function(x){
    x %>% dplyr::slice(rep(1:n(), each = unique(x$win_length))) %>%
      mutate(pos = seq(unique(x$win_start) , (unique(x$win_end)-1), 1))
  }) %>%
  bind_rows() %>%
  ungroup() %>%
  group_by(threshold, pos, win_length) %>%
  summarise(success = mean(success))

gg.swid <- sw_means %>%
    filter(threshold == 0.97) %>%
    ggplot(aes(x = pos, y=1)) +
      geom_tile(aes(fill=success))+
      scale_fill_viridis_c(option="plasma", labels = scales::percent) + 
    facet_wrap(win_length ~., ncol=1, strip.position ="left") +
    scale_x_continuous(limits = c(0, 712), breaks=seq(0,700,50), expand=c(0,0))  +
    theme_void() +
    theme(legend.position = "right",
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank()) +
  labs(fill = "% Identified",
       y = "Window size")


Fig3 <-  gg.primers / gg.entropy / gg.swid / gg.sequences  + plot_layout(heights= c(3, 3, 2, 0.5))   +  plot_annotation(tag_levels = 'A') 


pdf(file="fig/Fig3_COI_overview.pdf", width = 11, height = 8 , paper="a4r")
  plot(Fig3)
try(dev.off(), silent=TRUE)

```


# ID Success by primer
 
## Virtual PCR

```{r Virtual PCR}
# Load seqs
seqs <- readDNAStringSet("reference/merged_final.fa.gz")
seqs <- seqs[lengths(seqs)==712]

# Load primers
primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  mutate(seq = str_replace_all(seq, "I","N")) %>% 
  select(-score, -issues)

# Get all possible primer combinations
combos <- expand_grid(primers %>% filter(strand=="F") %>% pull(seq),
                      primers %>% filter(strand=="R") %>% pull(seq)
                      ) %>%
  mutate_if(is.factor, as.character)%>%
  unique() %>%
  magrittr::set_colnames(c("Fseq", "Rseq")) %>%
  left_join(primers %>% filter(strand=="F") %>% rename_all(. %>% paste0("F",.)), by="Fseq") %>%
  left_join(primers %>% filter(strand=="R") %>% rename_all(. %>% paste0("R",.)), by="Rseq") %>%
  mutate(amplicon = Rstart - Fend) %>%
  filter(amplicon > 50)

dir.create("primer_evaluation/amplicons")

# Setup multithreading
library(foreach)
library(doParallel)
cores=12
cl <- parallel::makeCluster(cores)
registerDoParallel(cl)

li <- foreach(p=1:nrow(combos)) %dopar% {
  #get primer names
  primernames <- paste0(combos$Fname[p], "_",  combos$Rname[p])
  
  # cut down alignments
  amplicon <- Biostrings::subseq(seqs, start=combos$Fend[p]+1, end = combos$Rstart[p]) #may need to add 1 to start
  
  if (any(!lengths(amplicon)== combos$amplicon[p])){
    warning(paste0("Amplicons of ",primernames, " are not the same length"))
  }
  
  maxgaps <- 9 # dont allow any more than 9 gaps
  rem <- names(amplicon)[Biostrings::letterFrequency(amplicon, "-") > maxgaps]
  amplicon <- amplicon[!names(amplicon) %in% rem]
  message(paste0(length(rem), " Sequences with more than ", maxgaps, " gaps removed from ", primernames))
  
  #write out sequences
  Biostrings::writeXStringSet(amplicon, file=paste0("primer_evaluation/amplicons/", primernames,".fa.gz"), compress=TRUE)
}
#close cluster
parallel::stopCluster(cl)
```


## USEARCH distance matrix

```{bash generate job index}
#!/bin/bash
dos2unix bash/usearch_distmat.sh
/usr/bin/ls -d /group/pathogens/Alexp/Metabarcoding/primer_evaluation/primer_evaluation/amplicons/* | sed -e '1p' -e '/.fa.gz/!d' | sort -u > job_index.txt
/usr/bin/ls -d /group/pathogens/Alexp/Metabarcoding/primer_evaluation/primer_evaluation/amplicons/win*/* | sed -e '1p' -e '/.fa.gz/!d' | sort -u > job_index.txt
njobs=$(cat job_index.txt | wc -l)
sbatch --array=1-$njobs bash/usearch_distmat.sh
```

## Figure 4 - ID success for different primers

```{r analyse uclust}
# Summarise number of mixed clusters that contain pests at %
pestlist <- read_csv("primer_evaluation/pestlist.csv") 

# Load primers
primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  mutate(seq = str_replace_all(seq, "I","N"))  %>%
  distinct()

# Get all possible primer combinations
combos <- expand_grid(primers %>% filter(strand=="F") %>% pull(seq),
                      primers %>% filter(strand=="R") %>% pull(seq)
                      ) %>%
  mutate_if(is.factor, as.character)%>%
  unique() %>%
  magrittr::set_colnames(c("Fseq", "Rseq")) %>%
  left_join(primers %>% filter(strand=="F") %>% rename_all(. %>% paste0("F",.)), by="Fseq") %>%
  left_join(primers %>% filter(strand=="R") %>% rename_all(. %>% paste0("R",.)), by="Rseq") %>%
  mutate(amplicon = Rstart - Fend) %>%
  filter( amplicon > 100)

# Check missing
complete <- list.files(path="primer_evaluation/amplicons/usearch_output/", pattern = ".txt.gz") %>%
  basename %>%
  str_remove(".txt.gz")

setdiff(paste0(combos$Fname, "_",  combos$Rname), complete)
setdiff(complete,paste0(combos$Fname, "_",  combos$Rname))


# Get mixed clusters
library(furrr)
plan(multiprocess, workers=4)
mixed_clusters <- fs::dir_ls(path="primer_evaluation/amplicons/usearch_output/", glob = "*.txt.gz")%>%
  furrr::future_map(function(x){
  #purrr::map(function(x){
  df <- vroom::vroom(x, delim="\t", col_names = c("acc1", "acc2", "dist")) %>%
    dplyr::mutate(spp1 = acc1 %>%
                    str_remove(";$") %>%
                    str_remove("^.*;"),
                  acc1 = acc1 %>% str_remove(";.*$"),
                  spp2 = acc2 %>%
                    str_remove(";$") %>%
                    str_remove("^.*;"),
                  acc2 = acc2 %>% str_remove(";.*$"),
                  dist = round(dist, 2)) %>%
    dplyr::filter(!spp1==spp2)

  all <- df %>%
        dplyr::group_by(dist) %>% 
        dplyr::summarise(mixed=n_distinct(spp1)) %>%
        dplyr::mutate(type="all")
  pests <- df %>%
        dplyr::group_by(dist) %>% 
        filter(spp1 %in% pestlist$Species) %>%
        dplyr::summarise(mixed=n_distinct(spp1)) %>%
        dplyr::mutate(type="pest")
      out <- bind_rows(all, pests)
      return(out)
  
  })%>%
  bind_rows(.id="source") %>%
  mutate(source = str_remove(basename(source), ".txt.gz"))
  
#Get amplified
amplified <- fs::dir_ls(path="primer_evaluation/amplicons/", glob = "*.fa.gz") %>%
   purrr::map(function(x){
   #furrr::future_map(function(x){
     df <- fasta.index(x) %>%
        mutate(species = desc %>% 
                 str_remove("(?:[^;]*;){7}") %>% #match 7th ;
                 str_remove(";$")) # match last ;
     all <- df %>%
      dplyr::group_by(filepath) %>%
      dplyr::summarise(seqs_amplified = n(), spp_amplified = n_distinct(species)) %>%
      dplyr::mutate(type="all")
     pests <- df %>%
      dplyr::group_by(filepath) %>%
      dplyr::filter(species %in% pestlist$Species) %>%
      dplyr::summarise(seqs_amplified = n(), spp_amplified = n_distinct(species)) %>%
      dplyr::mutate(type="pest")
     out <- bind_rows(all, pests)
    return(out)
   }) %>%
  bind_rows() %>%
  mutate(source = str_remove(basename(filepath), ".fa.gz")) %>%
  dplyr::select(-filepath)

joint <- mixed_clusters %>%
  left_join(amplified) %>%
  mutate(combos = source) %>% 
  tidyr::separate(source, into=c("Fname", "Rname"), sep="_", extra="merge")
#vroom::vroom_write(joint, "primer_evaluation/amplicons/mixed_clusters_summary.csv", delim=",")


# Make figure

# Count reads
joint <- vroom::vroom("primer_evaluation/amplicons/mixed_clusters_summary.csv", delim=",") %>%
  left_join(combos) %>% 
  mutate(success =  (spp_amplified - mixed)/spp_amplified,
         threshold = 1-dist) %>%
  dplyr::select(Fname,Rname, dist, threshold,
                mixed, type, seqs_amplified,
                spp_amplified, amplicon, combos, success) 


# Look at log ratio to the folmer region
ref <- joint %>% 
  dplyr::filter(Fname == "LCO1490"&  Rname=="HCO2198") %>% 
              select(ref_success = success,
                     dist, threshold, type) %>%
  dplyr::filter(threshold %in% c(0.97,0.98,0.99, 1))%>%
  group_by(type) %>%
  summarise(ref_success = mean(ref_success)) %>%
  ungroup()

id_success <- joint %>% 
  dplyr::filter(threshold %in% c(0.97,0.98,0.99, 1))%>%
  group_by(Fname, Rname, type, combos, amplicon, threshold) %>%
  summarise(success = mean(success)) %>%
  ungroup() %>%
  left_join(ref) %>%
  mutate(success_alr = log(success/ref_success),
         success_rat = success/ref_success,
         highlight = case_when(
           combos %in% c("fwhF2_fwhR2n", "fwhF2_HexCOIR4") ~ TRUE,
           TRUE ~ FALSE
         ))


# Breakpoint regression
model_dat <- id_success %>%
  dplyr::select(combos, amplicon, threshold, success)

library(chngpt)
breakpoint_fit <- model_dat %>% 
  group_by(threshold) %>%
  nest() %>%
  mutate(fits = map(data, ~chngptm(formula.1=success~1, formula.2=~amplicon,
                                   type="segmented", family="gaussian",data = .)),
         summary = map(fits, summary),
         preds = map2(fits, data, predict),
         breakpoint = map(fits, "chngpt"),
         breakpoint_ests = map(summary, function(x){ as.data.frame(t(x$chngpt))}),
         coef_info = map(summary,function(x){ as_tibble(x$coefficients, rownames="term" )}),
         )
  
# Get SE of breakpoints
breakpoint_fit %>% 
  unnest(breakpoint_ests) %>% 
 select(-where(is.list)) 

slope_coefs <- breakpoint_fit %>%
  unnest(coef_info) %>%
  dplyr::select(threshold,term, est, std_err = `Std. Error*`,
                lower = `(lower`, upper = `upper)`,
                pval = `p.value*`, -where(is.list)) %>%
  mutate(
    term = case_when(
    term == "(Intercept)" ~  "intercept",
    term == "amplicon" ~  "slope",
    term == "(amplicon-chngpt)+" ~ "post_slope"
    )) %>%
  mutate(signif = pval < 0.05) 


dat_pred <- breakpoint_fit %>%
  unnest(preds, data, breakpoint)%>%
  select(-where(is.list))  %>%
  drop_na() %>%
  left_join(slope_coefs %>%
              select(threshold, term, signif, est) %>%
              pivot_wider(names_from=term, values_from=c(signif, est))) 


break_annot <- dat_pred %>% 
  group_by(threshold) %>%
  filter(amplicon == breakpoint) %>%
  dplyr::slice(1) %>%
  select(-combos) %>%
  left_join(slope_coefs %>%
              filter(term == "post_slope") %>%
              select(threshold, pval, signif))

# Highest success
ref_annot <- id_success %>%
  mutate(type = type %>% str_replace("all", "All Insects") %>% str_replace("pest", "Pest Insects")) %>% 
  group_by(threshold, type) %>%
  filter(combos == "LCO1490_HCO2198")

gg.id <- id_success %>%
  mutate(type = type %>% str_replace("all", "All Insects") %>% str_replace("pest", "Pest Insects")) %>%
  ggplot(aes(x=amplicon, y=success, colour=success))+
  geom_jitter(width = 5, height=0.01, alpha=0.5)+
   geom_line(data=dat_pred[dat_pred$amplicon < dat_pred$breakpoint,],
             aes(x=amplicon, y=preds),  color = 'red', inherit.aes = FALSE) +
  geom_line(data=dat_pred[dat_pred$amplicon >= dat_pred$breakpoint,],
            aes(x=amplicon, y=preds, linetype=signif_post_slope),  color = 'red', inherit.aes = FALSE) +
  geom_point(data=break_annot, aes(x=amplicon, y=preds),  color = 'red', inherit.aes = FALSE) +
  geom_text(data=break_annot, aes(x=amplicon, y=preds,
                                  label=paste0(breakpoint, "bp")), #,ifelse(pval < 0.001,"<0.001", ">0.001")
            nudge_y = 0.1,nudge_x = 120,  color = 'red', inherit.aes = FALSE) +
  geom_text(data=ref_annot, aes(x=amplicon, y=success,label=paste0("Max: ",round((success* 100),2), "%")),
            nudge_y = 0.05,  color = 'blue', inherit.aes = FALSE) +
  geom_vline(data=dat_pred, aes(xintercept = breakpoint), colour="black", linetype = "dashed") +
  scale_colour_gradient(low ="firebrick", high ="darkslateblue", na.value = "grey") +
  geom_hline(yintercept=0, colour="grey80")+
  base_theme+
  facet_grid(type~threshold) +
  theme(legend.position = "none") + 
  labs(x="Amplicon length",
       y="Successfully identified") +
  coord_cartesian(ylim=c(0.5,1))+
  scale_linetype_manual(values=c( "dashed", "solid"))+
  scale_y_continuous(labels = scales::percent) +
  scale_x_continuous(labels=scales::unit_format(unit="bp"))+
  theme(panel.grid.minor = element_blank())

gg.id

```

## ID success on tree

for this we will analyse just the LCO HCO data. Will need to take in the raw amplicons data

Arrange this on the tree and see how much phylogenetic signal there is

```{r ID success on tree}
# get Lineage for tree
seqs <- insect::readFASTA("reference/merged_final.fa.gz")

seqs <- acc2hex(seqs)

lineage <- names(seqs) %>%
  str_split_fixed(pattern="\\|", n = 2) %>%
  as_tibble() %>%
  separate(V2, into=c("taxid","Kingdom", "Phylum", 
    "Class", "Order", "Family", "Genus", "Species"), sep=";") %>%
  dplyr::rename(acc = V1)%>%
  mutate(Species = Species %>% str_replace_all(" ", "_")) %>%
  dplyr::select(-Species)

upper_lineage <- c(0.97, 0.98,0.99,1) %>%
      purrr::map(~{
        lineage %>% select(-taxid, -acc) %>%
          distinct() %>%
          mutate(threshold = .x)
      }) %>%
      bind_rows()

# Get mixed clusters for the LCO-HCO gene region
folmer_id <- vroom::vroom("primer_evaluation/amplicons/usearch_output/LCO1490_HCO2198.txt.gz",
                          delim="\t", col_names = c("acc1", "acc2", "dist")) %>%
    dplyr::mutate(spp1 = acc1 %>%
                    str_remove(";$") %>%
                    str_remove("^.*;"),
                  acc1 = acc1 %>% str_remove(";.*$"),
                  spp2 = acc2 %>%
                    str_remove(";$") %>%
                    str_remove("^.*;"),
                  acc2 = acc2 %>% str_remove(";.*$"),
                  dist = round(dist, 2)) %>%
    mutate(threshold = 1-dist) %>%
    filter(threshold %in% c(0.97, 0.98,0.99,1)) %>%
    dplyr::filter(!spp1==spp2)%>%
    dplyr::group_by(threshold, spp1) %>% 
    dplyr::summarise(mixed=n_distinct(spp2)) %>%
    ungroup() %>%
    mutate(Genus = spp1 %>% str_remove(" .*$")) 

folmer_id <- folmer_id %>%
    right_join(upper_lineage) %>%
    mutate(mixed = replace_na(mixed, 0)) %>%
    group_by(Family, threshold) %>%
    dplyr::summarise(mixed=mean(mixed)) # Could do sum instead

# Arrange on tree
tree <- ape::read.tree("reference/trees/ultrametric_insecta_tree_order_constrained.nwk")

# Prune tree to genus
tips_to_keep <- tree$tip.label %>% 
  enframe() %>% 
  tidyr::separate(value, into=c("acc", "Species"), sep="\\|") %>%
  left_join(lineage, by="acc") %>%
  filter(!is.na(Family)) %>%
  group_by(Family) %>%
  dplyr::slice(1) %>%
  ungroup() %>%
  mutate(tips = paste0(acc,"|", Species))


#Get subtree of only genera
genus_tree  <- castor::get_subtree_with_tips(tree,
                                          only_tips = tips_to_keep$tips,
                                          collapse_monofurcations=TRUE,
                                          force_keep_root=TRUE)$subtree


#Prune names to Family
genus_tree$tip.label <- genus_tree$tip.label %>%
  str_remove("\\|.*$")%>%
  enframe() %>%
  mutate(acc = value)%>%
  left_join(lineage) %>%
  pull(Family)

# Filter id sucess to just those in tree
folmer_id_filtered <- folmer_id %>%
  dplyr::filter(Family %in%  genus_tree$tip.label)

Ntips 	<- length(genus_tree$tip.label)
Nnodes 	<- genus_tree$Nnode
cat(sprintf("Tree has %d nodes, %d tips and %d edges\n",Nnodes,Ntips,nrow(genus_tree$edge)));

# create internal node labels
genus_tree$node.label <- NA
if(is.na(genus_tree$node.label)){
	cat(sprintf("Adding node labels to full tree..\n"))
	genus_tree$node.label = paste("node.", 1:Nnodes, sep = "") # don't use underscores, because some tree readers (e.g. rncl) interpret them as spaces
}

# replace zero-length edges
if(any(genus_tree$edge.length==0)){
  epsilon = 0.1*min(genus_tree$edge.length[genus_tree$edge.length>0])
	cat(sprintf("Note: Some edges have length zero, which may break some of the HSP routines. Replacing zero-lengths with a tiny positive length (%g)..\n",epsilon))
	genus_tree$edge.length[genus_tree$edge.length==0] = epsilon
}

# Plot tree

# Loop over all different dists
thresholds <- unique(folmer_id_filtered$threshold)
plotvec <- vector("list", length = length(thresholds))
names(plotvec) <- thresholds

i=1
for(i in 1:length(thresholds)){

    p1 <- ggtree(genus_tree , ladderize=TRUE, aes(colour=values), layout = "circular") 
  
  weights_p1 <- p1$data %>%
    left_join(folmer_id_filtered %>% 
                filter(threshold == thresholds[i]) %>%
                select(-threshold) %>%
                dplyr::rename(label = Family, values = mixed))%>%
    mutate(values = values %>% replace_na(0))
                
      
  tip_states <- weights_p1 %>%
    dplyr::filter(isTip) %>%
    pull(values)
  names(tip_states) <- weights_p1 %>%
    dplyr::filter(isTip) %>%
    pull(label)
  
  weights_p1$values[!weights_p1$isTip] <- castor::asr_independent_contrasts(tree=genus_tree,
                                                          tip_states=tip_states, check_input = FALSE)$ancestral_states

  p2 <- p1 %<+% weights_p1 +
    scale_color_gradient(low="darkslateblue", high="firebrick",na.value = NA, limits = c(0,5), oob = scales::squish) +
    theme(legend.position = "none") + 
    scale_y_continuous(expand=c(0,0))+ 
    scale_x_discrete(expand=c(0,0)) 
  
  # Add heatmap
  plot_dat <- p1$data %>%
    left_join(folmer_id_filtered %>%
    filter(threshold == thresholds[i]) %>%
    select(-threshold) %>%
    dplyr::rename(label = Family, values = mixed)) %>%
    mutate(values = values %>% replace_na(0)) %>% #Use 1 to not mess with log10 transform
    filter(!is.na(label)) %>%
    column_to_rownames("label") %>%
    select(values) %>%
    as.data.frame()
  
  
  p3 <- gheatmap(p2,plot_dat, offset=0, width=.1, color=NA, legend_title = NA, colnames  = FALSE,
    colnames_angle=95, colnames_offset_y = 0) +
    #scale_fill_viridis_c(option="C", name="Pest Spp.", trans="log10")  #, trans="log10"
    scale_fill_gradient(low="darkslateblue", high="firebrick",na.value = NA, limits = c(0,5), oob = scales::squish)+
    theme(legend.position = "none")
  
  plotvec[[i]] <- p2

}

# Autocorrelation
tree <- ape::read.tree("reference/trees/ultrametric_insecta_tree_order_constrained.nwk")

# Get mixed clusters for the LCO-HCO gene region
folmer_id_spp <- vroom::vroom("primer_evaluation/amplicons/usearch_output/LCO1490_HCO2198.txt.gz",
                          delim="\t", col_names = c("acc1", "acc2", "dist")) %>%
    dplyr::mutate(spp1 = acc1 %>%
                    str_remove(";$") %>%
                    str_remove("^.*;"),
                  acc1 = acc1 %>% str_remove(";.*$"),
                  spp2 = acc2 %>%
                    str_remove(";$") %>%
                    str_remove("^.*;"),
                  acc2 = acc2 %>% str_remove(";.*$"),
                  dist = round(dist, 2)) %>%
    mutate(threshold = 1-dist) %>%
    filter(threshold %in% c(0.97, 0.98,0.99,1)) %>%
    dplyr::filter(!spp1==spp2)%>%
    dplyr::group_by(threshold, spp1) %>% 
    dplyr::summarise(mixed=n_distinct(spp2), acc1) %>%
    ungroup() %>%
  mutate(tips = paste0(acc1 %>% str_remove("\\|.*$") %>% acc2hex(.), "|", spp1 %>% str_replace_all(" ", "_"))) %>%
  select(threshold, tips, values = mixed)

thresholds <- unique(folmer_id_spp$threshold)
acfvec <- vector("list", length = length(thresholds))
names(acfvec) <- thresholds
traitvec <- vector("list", length = length(thresholds))
names(traitvec) <- thresholds

i=1
for(i in 1:length(thresholds)){
  weights <- tree$tip.label %>% 
    enframe() %>% 
    select(-name, tips = value) %>%
      left_join(folmer_id_spp %>% 
                  filter(threshold == thresholds[i]) %>%
                  select(-threshold)) %>%
     mutate(values = replace_na(values, 0))
  
  tip_states <- weights %>%
    dplyr::pull(values)
  names(tip_states) <- weights %>%
    dplyr::pull(tips)
  
  # Autocorrelation funciton
  acf <- castor::get_trait_acf(tree, tip_states, Npairs=1e8, Nbins=100)
  
  # Trait depth
  tip_states_binary <- tip_states
  tip_states_binary[tip_states_binary >0] <- 1
  consentrait <- get_trait_depth(tree, tip_states_binary,
                                 min_fraction = 0.9, #90% of clade must be insufficiently ID'd to be problmeatic
                                 count_singletons=TRUE, weighted=FALSE, Npermutations = 1000)
  
  # Create output data frame
  acfvec[[i]] <- data.frame(
    distances = acf$distances,
    acf_acf = acf$autocorrelations,
    acf_mean_abs = acf$mean_abs_differences,
    acf_mean_rel = acf$mean_rel_differences,
    acf_npairs = acf$Npairs_per_distance)
  
  pos_clades <- consentrait$positive_clades
  traitvec[[i]] <-  data.frame(
    pos_clade_id = pos_clades,
    traits_per_pos_clades = consentrait$positives_per_clade[pos_clades],
    mean_depth_pos_clades = consentrait$mean_depth_per_clade[pos_clades]
  )

}

acf <- acfvec %>%
  bind_rows(.id="threshold") %>%
  group_by(threshold) %>%
  pivot_longer(starts_with("acf_"),
               names_to="type",
               values_to="value")



gg.acf <- acf %>% 
  filter(type == "acf_acf", distances < 16) %>%
  ggplot(aes(x = distances, y=value)) +
  geom_line(colour="darkslateblue") +
  base_theme+
  facet_grid(~threshold) +
  theme(legend.position = "none") + 
  labs(x="Phylogenetic distance",
       y="Pearson correlation") +
  scale_y_continuous(labels = scales::percent) #+
  #theme(panel.grid.minor = element_blank())

gg.acf


# Consentrait metric - should this go on the plot?
bad_clades <- traitvec %>%
  bind_rows(.id="threshold")

#clade labels
bad_clades_labels <- bad_clades %>%
  group_by(threshold) %>%
  arrange(desc(traits_per_pos_clades),desc(mean_depth_pos_clades), .by_group = TRUE) %>%
  rownames_to_column("rank") %>%
  mutate(rank = as.numeric(rank)) %>%
    top_n(-5, rank) %>%
    #top_frac(-.001, rank) %>%
  mutate(subtree_taxonomy = map(pos_clade_id,function(x){
    subtree <- castor::get_subtree_at_node(tree, x-Ntip(tree))$subtree
    taxonomy <- subtree$tip.label %>%
      enframe() %>%
      mutate(acc= value %>% str_remove("\\|.*$"))%>%
      left_join(lineage, by="acc")
    names(which.max(table(taxonomy$Family)))
  }))%>% 
  unnest(subtree_taxonomy) %>%
  filter(!duplicated(subtree_taxonomy))

library(ggrepel)

gg.bad_clades <- bad_clades %>% 
  ggplot(aes(x= mean_depth_pos_clades, y=traits_per_pos_clades, colour=mean_depth_pos_clades)) + 
  geom_point(alpha=0.2) + 
  geom_point(data = bad_clades_labels, aes(x=mean_depth_pos_clades, y=traits_per_pos_clades), colour="red")+
  geom_text_repel(data = bad_clades_labels, aes(x=mean_depth_pos_clades, y=traits_per_pos_clades, label= subtree_taxonomy), colour="red")+
  scale_y_log10()+
  scale_colour_gradient(low ="darkslateblue", high ="firebrick", na.value = "grey") +
    facet_grid(~threshold) +
  base_theme+
  theme(legend.position = "none") + 
    labs(x="Mean phylogenetic depth",
         y="Failed IDs")

# Or could pull out the positive clades, then get the descnedants for htem


# Plot figure 4 
#Fig4a <- plotvec[[1]] / plotvec[[2]] / plotvec[[3]] / plotvec[[4]]
#Fig4b <- gg.id + gg.acf + gg.bad_clades + plot_layout(widths = c(3,1,1))

#Fig4 <- Fig4a - Fig4b + plot_layout(widths = c(1,3)) + plot_annotation(tag_levels = "A")

Fig4 <-  gg.id / gg.acf / gg.bad_clades + plot_layout(heights = c(2,1,1)) + plot_annotation(tag_levels = "A")

pdf(file="fig/Fig4_id_success.pdf", width = 11, height = 8 , paper="a4r")
  plot(Fig4)
try(dev.off(), silent=TRUE)

```


# Predicted mismatch


```{r Primerminer, message=FALSE}
library(PrimerMiner)
## Target sequences to test against
seqs <- insect::readFASTA("reference/merged_final.fa.gz")
names(seqs) <- names(seqs) %>% str_replace_all(" ", "_")
writeFASTA(seqs, "primer_evaluation/merged_final_target.fa")

target <- "primer_evaluation/merged_final_target.fa"

# Load primers
primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  mutate(seq = str_replace_all(seq, "I","N")) %>% 
  select(-score, -issues)

dir.create("primer_evaluation/PrimerMiner")

for (i in 1:nrow(primers)) {
  if(primers$strand[i]=="F"){
  evaluate_primer(target,
   as.character(primers$seq[i]), primers$start[i], primers$end[i],
   forward = TRUE, gap_NA = TRUE, N_NA=TRUE,
   mm_position = "Position_v1", mm_type = "Type_v1", adjacent = 2,
   save = paste0("primer_evaluation/PrimerMiner/", primers$name[i],".csv")
  )
  } else if(primers$strand[i]=="R"){
  evaluate_primer(target,
   as.character(primers$seq[i]), primers$start[i], primers$end[i],
   forward = FALSE, gap_NA = TRUE, N_NA=TRUE,
   mm_position = "Position_v1", mm_type = "Type_v1", adjacent = 2,
   save = paste0("primer_evaluation/PrimerMiner/", primers$name[i],".csv")
  )
 }
}

# gZip files
fs::dir_ls(path="primer_evaluation/PrimerMiner", glob = "*.csv") %>%
  purrr::map(R.utils::gzip)

```

## Figure 5 - Mismatch

```{r figure 4}
# Load primers
primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  mutate(seq = str_replace_all(seq, "I","N")) %>% 
  select(-score, -issues) %>%
  distinct()

#Read in all files

dat <- fs::dir_ls(path="primer_evaluation/PrimerMiner", glob = "*.csv|*.csv.gz") %>%
  purrr::set_names() %>%
  map_dfr(vroom::vroom, col_select= list("Template", "sequ", "sum"),
          .id = "source", progress=FALSE) %>%
  mutate(Template = str_remove(Template, ";$"))%>%
  separate(col=Template, into=c("Acc","Kingdom","Phylum","Class","Order","Family","Genus","Species"), sep=";") %>%
  dplyr::rename(Sequence = sequ) %>% 
  dplyr::mutate(primer = source %>% 
                  basename() %>%
                  str_remove(".csv") %>%
                  str_remove(".gz$")) %>%
  dplyr::select(primer,Acc, Genus, species, sum)

vroom::vroom_write(dat, "primer_evaluation/mismatch_all.csv.gz",delim = ",")

genus_summaries <- vroom::vroom("primer_evaluation/mismatch_all.csv.gz", delim = ",") %>%
  tidyr::separate(Acc, into=c("Acc", "tax_id"), sep="\\|") %>%
  group_by(primer, Genus, tax_id) %>% #Group by higher to minimize plotting
  summarise(sum = mean(sum, na.rm=TRUE)) %>%
  ungroup()%>%
  mutate(dup = paste0(primer, Genus)) %>% 
  filter(!duplicated(dup)) %>% #remove any duplicates
  dplyr::select(-dup) %>%
  left_join(primers %>%
            dplyr::select(primer = name, strand))

#vroom::vroom_write(genus_summaries, "primer_evaluation/mismatch_summary.csv.gz",delim = ",")

genus_summaries <- vroom::vroom("primer_evaluation/mismatch_summary.csv.gz",delim = ",")

# Arrange on tree
tree <- ape::read.tree("reference/trees/ultrametric_insecta_tree_order_constrained.nwk")

# Filter summaries to just those in tree
genus_summaries <- genus_summaries %>% 
  dplyr::filter(Genus %in% (tree$tip.label %>% 
  str_remove("^.*\\|") %>%
  str_extract("^.+?(?=_)") %>%
    unique()))

# get Lineage
seqs <- insect::readFASTA("reference/merged_final.fa.gz")

seqs <- acc2hex(seqs)

lineage <- names(seqs) %>%
  str_split_fixed(pattern="\\|", n = 2) %>%
  as_tibble() %>%
  separate(V2, into=c("taxid","Kingdom", "Phylum", 
    "Class", "Order", "Family", "Genus", "Species"), sep=";") %>%
  dplyr::rename(acc = V1)%>%
  mutate(Species = Species %>% str_replace_all(" ", "_")) %>%
  dplyr::select(-Species)

# Prune tree to genus
tips_to_keep <- tree$tip.label %>% 
  enframe() %>% 
  tidyr::separate(value, into=c("acc", "Species"), sep="\\|") %>%
  left_join(lineage, by="acc") %>%
  filter(Genus %in% (genus_summaries %>% pull(Genus))) %>%
  group_by(Genus) %>%
  dplyr::slice(1) %>%
  ungroup() %>%
  mutate(tips = paste0(acc,"|", Species))


#Get subtree of only genera
genus_tree  <- castor::get_subtree_with_tips(tree,
                                          only_tips = tips_to_keep$tips,
                                          collapse_monofurcations=TRUE,
                                          force_keep_root=TRUE)$subtree

#Prune names to genus
genus_tree$tip.label <- genus_tree$tip.label %>% 
  str_remove("^.*\\|") %>%
  str_extract("^.+?(?=_)")

#Prune again to ensure matching tips
genus_tree <- castor::get_subtree_with_tips(genus_tree,
                                          only_tips = genus_tree$tip.label[genus_tree$tip.label %in% genus_summaries$Genus],
                                          collapse_monofurcations=TRUE,
                                          force_keep_root=TRUE)$subtree

Ntips 	<- length(genus_tree$tip.label)
Nnodes 	<- genus_tree$Nnode
cat(sprintf("Tree has %d nodes, %d tips and %d edges\n",Nnodes,Ntips,nrow(genus_tree$edge)));

# create internal node labels
genus_tree$node.label <- NA
if(is.na(genus_tree$node.label)){
	cat(sprintf("Adding node labels to full tree..\n"))
	genus_tree$node.label = paste("node.", 1:Nnodes, sep = "") # don't use underscores, because some tree readers (e.g. rncl) interpret them as spaces
}

# replace zero-length edges
if(any(genus_tree$edge.length==0)){
  epsilon = 0.1*min(genus_tree$edge.length[genus_tree$edge.length>0])
	cat(sprintf("Note: Some edges have length zero, which may break some of the HSP routines. Replacing zero-lengths with a tiny positive length (%g)..\n",epsilon))
	genus_tree$edge.length[genus_tree$edge.length==0] = epsilon
}


## Get values for higher nodes with castor
uprimers <- unique(genus_summaries$primer)
p_weights <- vector("list", length=length(uprimers))
names(p_weights) <- uprimers

for (i in 1:length(uprimers)){
  print(paste0("Processing Primer ",i, " of ", length(uprimers), ": ", uprimers[i]))
  tip_states <- genus_summaries %>%
    dplyr::filter(primer==uprimers[i], Genus %in% tips_to_keep$Genus) %>%
    #group_by(Genus) %>%
    #summarise(values = mean(sum, na.rm=TRUE))%>%
    #ungroup() %>%
    dplyr::rename(values = sum) %>%
    column_to_rownames("Genus")
    
  row2tip <- match(rownames(tip_states), genus_tree$tip.label)
  
  #find non matching
  rownames(tip_states)[is.na(row2tip)]
  
  tip_states <- tip_states[!is.na(row2tip),,drop = FALSE]
  hsp_states <- castor::hsp_independent_contrasts(tree = genus_tree,
                                              tip_states = tip_states$values,
                                              weighted = TRUE,
                                              check_input = TRUE)$states
  
  # Get distance of each tip to tips that have data
  target_tips <- match(tip_states %>% filter(!is.na(values)) %>% rownames(), genus_tree$tip.label);
  tip_dist <- castor::find_nearest_tips(genus_tree, only_descending_tips=FALSE, 
                                        target_tips=target_tips, as_edge_counts=FALSE, check_input=TRUE)
  
   p_weights[[i]] <- tip_states %>%
    rownames_to_column("Genus") %>%
    mutate(hsp = hsp_states[1:Ntips],
           tip_dist =tip_dist$nearest_distance_per_tip[1:Ntips])
}

imputed <- genus_summaries %>%
    left_join(bind_rows(p_weights,.id = "primer"), 
               by = c("primer", "Genus", "tax_id", "strand")) %>%
  select(-strand) %>%
  left_join(primers %>%
            dplyr::select(primer = name, degeneracy, strand))%>%
  filter(!is.na(hsp))

primer_orders <- imputed %>%
  group_by(primer) %>%
  dplyr::summarise(hsp = mean(hsp, na.rm=TRUE), sum = mean(sum, na.rm=TRUE)) %>%
  arrange(hsp)

# Plot tree
p1 <- ggtree(genus_tree , ladderize=TRUE, aes(colour=values))

weights_p1 <- p1$data %>%
  left_join(imputed %>%
              group_by(Genus) %>%
              summarise(values = mean(sum, na.rm=TRUE))%>%
              dplyr::rename(label = Genus)
    )  


tip_states <- weights_p1 %>%
  dplyr::filter(isTip) %>%
  pull(values)
names(tip_states) <- weights_p1 %>%
  dplyr::filter(isTip) %>%
  pull(label)

weights_p1$values[!weights_p1$isTip] <- castor::asr_independent_contrasts(tree=genus_tree,
                                                        tip_states=tip_states)$ancestral_states

p2 <- p1 %<+% weights_p1 +
  #geom_tippoint(aes(colour=values)) +
  scale_color_gradient(low="darkslateblue", high="firebrick") +
  theme(legend.position = "none") + 
  scale_y_continuous(expand=c(0,0))+ 
  scale_x_discrete(expand=c(0,0)) 

## make a clade label list
tax_groups <- tips_to_keep %>%
  dplyr::rename(label = Genus) %>%
  select(label, Order) %>%
  filter(label %in% genus_tree$tip.label) %>%
  group_by(Order) 

group_name <- group_keys(tax_groups)  %>%
  mutate(group_name = Order %>% str_remove_all("\\[|\\]"))

cls <- tax_groups %>% 
  group_split() %>% 
  purrr::map(pull, label) %>%
  set_names(group_name$group_name) %>%
  purrr::map(function(x){
    query <- x
    labs <-  p2$data %>%
      dplyr::filter(label %in% query)
    quants <- labs  %>% 
      dplyr::filter(between(y, left=quantile(labs$y,  probs =0.1), right=quantile(labs$y,  probs =0.90)))
    mrca_node <- get_mrca_of_set(genus_tree, quants$label)
    
    if(mrca_node > Ntips){
      subset_node <- mrca_node-Ntips
    } else{
      subset_node <- mrca_node
    }
    subset_tree <- get_subtree_at_node(genus_tree, subset_node)$subtree
    print(length(subset_tree$tip.label))
    
    # Only label the bigger ones
    if(length(subset_tree$tip.label) < 1000){
      mrca_node <- NULL
    }
    
    return(mrca_node)
  })

#drop small nodes
cls <- cls[!sapply(cls, is.null)]

# colours 
colourCount = length(cls)
getPalette = colorRampPalette(brewer.pal(12, "Paired"))
colour.pal <- getPalette(colourCount)

p3 <- p2
for(i in 1:length(cls)){
p3 <- p3 + geom_cladelabel(node=cls[[i]], label=names(cls[i]), align=T, angle=270, hjust='center', offset.text=.5, barsize=1.5, color = colour.pal[[i]])
}

p3

# Plot heatmap
gg.mismatch <- imputed %>%
  left_join(p2$data %>% dplyr::select(label, y) %>% dplyr::rename(Genus = label)) %>%
  mutate( primer = factor(primer, levels=primer_orders$primer)) %>%     
  ggplot(aes(x = primer, y = y, fill = hsp)) +
    geom_raster() +
  #scale_fill_distiller(palette = 'RdYlBu', limits = c(0, 200), oob = scales::squish)+
    scale_fill_gradient(low = "darkslateblue", high = "firebrick", na.value = "grey", limits = c(0, 200), oob = scales::squish) +
    facet_grid(~strand, scales="free", space="free", drop=TRUE) +
    #theme_classic() + 
    theme(
      axis.text.x = element_blank(),
      axis.ticks = element_blank(),
      axis.text.y = element_blank(),
      axis.title = element_blank(),
      strip.text.y = element_text(angle = 0),
      #strip.background = element_rect(fill="grey10"),
      legend.position = "none"
    ) + 
  scale_y_continuous(expand=c(0,0))+ 
  scale_x_discrete(expand=c(0,0))

# Density plot of mismatch
gg.density <- imputed %>%
  left_join(p2$data %>% dplyr::select(label, y) %>% dplyr::rename(Genus = label)) %>%
  group_by(Genus, y) %>%
  summarise(values = mean(sum, na.rm=TRUE)) %>%
  ggplot(aes(x = y, y=values, fill=values, colour=values)) +
  geom_point(size=0.01, alpha=0.5)+
  #geom_smooth(span = 0.1)+
  scale_colour_gradient(low="darkslateblue", high="firebrick") + 
  scale_x_continuous(expand=c(0,0)) +
  scale_y_continuous(expand=c(0,0)) +
  theme_void() +
  theme(legend.position = "none")+
  coord_flip()

# plot tip dist (missing data), mean mismatch, evenness of mismatch, and degeneracy
library(DescTools)

gg.primer_stats <- imputed %>%
   mutate(primer = factor(primer, levels=primer_orders$primer)) %>%     
  group_by(primer, strand) %>%
  summarise(
    tip_dist = mean(tip_dist),
    mean_mismatch = mean(hsp, na.rm=TRUE),
    gini_mismatch = Gini(hsp),
    degeneracy = mean(degeneracy)
    ) %>%
  pivot_longer(3:6, 
               names_to="measure",
               values_to="value") %>%
  mutate(measure = factor(measure, levels = c("mean_mismatch", "gini_mismatch", "degeneracy", "tip_dist"))) %>%
  group_by(measure) %>%
  mutate(cols = value) %>%
  mutate_at(c("cols"),  ~ . / max(.) ) %>%
  ggplot(aes(x = primer, y = value, fill=cols)) +
    geom_col() +
    scale_fill_gradient(low = "darkslateblue", high = "firebrick", na.value = "grey",  oob = scales::squish) +
    facet_grid(measure~strand, scales="free", switch="y", drop=TRUE) +
  base_theme+
    theme(
      axis.title.y = element_blank(),
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),
      strip.text.x = element_blank(),
      strip.text.y = element_text(angle=0),
      legend.position = "none"
    ) + 
  scale_y_continuous(expand=c(0,0))+ 
  scale_x_discrete(expand=c(0,0))

Fig5a <- p3 + gg.mismatch + gg.density + plot_layout(widths = c(1,4,0.25))
Fig5b <- plot_spacer() + gg.primer_stats + plot_spacer() + plot_layout(widths = c(1,4,0.25))

Fig5 <- Fig5a / Fig5b + plot_layout(heights = c(7, 1))

Fig5
pdf(file="fig/Fig5_mismatch.pdf", width = 8, height = 11 , paper="a4")
  plot(Fig5)
try(dev.off(), silent=TRUE)
 
## Supplementary plot of unimputed mismatch
  
  
# Plot heatmap
gg.mismatch_un <- imputed %>%
  left_join(p2$data %>% dplyr::select(label, y) %>% dplyr::rename(Genus = label)) %>%
  mutate( primer = factor(primer, levels=primer_orders$primer)) %>%     
  ggplot(aes(x = primer, y = y, fill = sum)) +
    geom_raster() +
  #scale_fill_distiller(palette = 'RdYlBu', limits = c(0, 200), oob = scales::squish)+
    scale_fill_gradient(low = "darkslateblue", high = "firebrick", na.value = "grey", limits = c(0, 200), oob = scales::squish) +
    facet_grid(~strand, scales="free", space="free", drop=TRUE) +
    #theme_classic() + 
    theme(
      axis.text.x = element_blank(),
      axis.ticks = element_blank(),
      axis.text.y = element_blank(),
      axis.title = element_blank(),
      strip.text.y = element_text(angle = 0),
      #strip.background = element_rect(fill="grey10"),
      legend.position = "none"
    ) + 
  scale_y_continuous(expand=c(0,0))+ 
  scale_x_discrete(expand=c(0,0))

# plot tip dist (missing data), mean mismatch, evenness of mismatch, and degeneracy
library(DescTools)

gg.primer_stats_un <- imputed %>%
   mutate(primer = factor(primer, levels=primer_orders$primer)) %>%     
  group_by(primer, strand) %>%
  summarise(
    tip_dist = mean(tip_dist),
    mean_mismatch = mean(sum, na.rm=TRUE),
    gini_mismatch = Gini(sum),
    degeneracy = mean(degeneracy)
    ) %>%
  pivot_longer(3:6, 
               names_to="measure",
               values_to="value") %>%
  mutate(measure = factor(measure, levels = c("mean_mismatch", "gini_mismatch", "degeneracy", "tip_dist"))) %>%
  group_by(measure) %>%
  mutate(cols = value) %>%
  mutate_at(c("cols"),  ~ . / max(.) ) %>%
  ggplot(aes(x = primer, y = value, fill=cols)) +
    geom_col() +
    scale_fill_gradient(low = "darkslateblue", high = "firebrick", na.value = "grey",  oob = scales::squish) +
    facet_grid(measure~strand, scales="free", switch="y", drop=TRUE) +
  base_theme+
    theme(
      axis.title.y = element_blank(),
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),
      strip.text.x = element_blank(),
      strip.text.y = element_text(angle=0),
      legend.position = "none"
    ) + 
  scale_y_continuous(expand=c(0,0))+ 
  scale_x_discrete(expand=c(0,0))

sup3a <- p3 + gg.mismatch_un + gg.density + plot_layout(widths = c(1,4,0.25))
sup3b <- plot_spacer() + gg.primer_stats_un + plot_spacer() + plot_layout(widths = c(1,4,0.25))

sup3 <- sup3a / sup3b + plot_layout(heights = c(7, 1))

sup3
pdf(file="fig/supplementary/sup_mismatch.pdf", width = 8, height = 11 , paper="a4")
  plot(sup3)
try(dev.off(), silent=TRUE)
```

# ACF Mismatch
```{r autocrrelation}
tree <- ape::read.tree("reference/trees/ultrametric_insecta_tree_order_constrained.nwk")

primer_mismatch <- vroom::vroom("primer_evaluation/mismatch_all.csv.gz",delim = ",") %>% 
  mutate(Acc = Acc %>% str_remove("\\|.*$") %>%
           acc2hex()) %>%
  mutate(tips = paste0(Acc, "|", Species)) %>%
  select(primer, tips, values = sum)


uprimers <- unique(primer_mismatch$primer)
acfvec <- vector("list", length=length(uprimers))
names(acfvec) <- uprimers
traitvec <- vector("list", length = length(uprimers))
names(traitvec) <- uprimers

i=1
for (i in 1:length(uprimers)){
  weights <- tree$tip.label %>% 
      enframe() %>% 
      select(-name, tips = value) %>%
        left_join(primer_mismatch %>%
                    filter(primer == uprimers[i]))%>%
      filter(!is.na(values))


  # Subset to only those with known states
  subset_tree <- get_subtree_with_tips(tree, weights$tips)$subtree
        print(length(subset_tree$tip.label))
  message(length(subset_tree$tip.label), " tips with known states kept for ", uprimers[i])

  # Get tip states
  tip_states <- weights %>%
    dplyr::pull(values)
  names(tip_states) <- weights %>%
    dplyr::pull(tips)
  
  # Autocorrelation funciton
  acf <- castor::get_trait_acf(subset_tree, tip_states, Npairs=1e8, Nbins=100)
  
 # # Trait depth
 # tip_states_binary <- tip_states
 # tip_states_binary[tip_states_binary >0] <- 1
 # consentrait <- get_trait_depth(subset_tree, tip_states_binary,
 #                                min_fraction = 0.9, #90% of clade must be insufficiently ID'd to be problmeatic
 #                                count_singletons=TRUE, weighted=FALSE, Npermutations = 1000)
 # 
  # Create output data frame
  acfvec[[i]] <- data.frame(
    distances = acf$distances,
    acf_acf = acf$autocorrelations,
    acf_mean_abs = acf$mean_abs_differences,
    acf_mean_rel = acf$mean_rel_differences,
    acf_npairs = acf$Npairs_per_distance)
  
 #pos_clades <- consentrait$positive_clades
 #traitvec[[i]] <-  data.frame(
 #  pos_clade_id = pos_clades,
 #  traits_per_pos_clades = consentrait$positives_per_clade[pos_clades],
 #  mean_depth_pos_clades = consentrait$mean_depth_per_clade[pos_clades]
 #)
}

acf <- acfvec %>%
  bind_rows(.id="primer")

vroom::vroom_write(acf, "primer_evaluation/acf_mismatch.csv.gz",delim = ",")

consentrait <- traitvec %>%
  bind_rows(.id="primer")
vroom::vroom_write(consentrait, "primer_evaluation/consentrait_mismatch.csv.gz",delim = ",")


acf <- vroom::vroom("primer_evaluation/acf_mismatch.csv.gz") %>%
    filter(acf_npairs > 0)  %>%

# Load primers
primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  mutate(seq = str_replace_all(seq, "I","N")) %>% 
  select(-score, -issues, primer= name) %>%
  distinct() %>%
  left_join(primer_mismatch %>%
  group_by(primer) %>%
  summarise(
    mean_mismatch = mean(values, na.rm=TRUE)
    )
  )

gg.facf <- acf %>%
  left_join(primers) %>%
  select(-acf_npairs) %>%
  group_by(primer) %>%
  pivot_longer(starts_with("acf_"),
               names_to="type",
               values_to="value") %>%
  ungroup() %>%
 filter(type == "acf_acf", strand=="F") %>%
  mutate(new_order = factor(primer, levels = unique(primer[order(mean_mismatch)]))) %>%
#  mutate(primer = fct_reorder(primer, mean_mismatch)) %>%
ggplot(aes(x = distances, y=value)) +
  geom_line(alpha=1, colour="black") +
  geom_text(data=primers %>%
              filter(strand=="F") %>%
              mutate(new_order = factor(primer, levels = unique(primer[order(mean_mismatch)]))), aes(label = paste0("MM:", round(mean_mismatch,1)), x=2, y=-0.6), inherit.aes = FALSE, colour="red", hjust=0, check_overlap = TRUE) +
  base_theme +
  facet_wrap(~new_order) +
  labs(y = "Pearson correlation",
       x = "Phylogenetic distance",
       title = "Forward primers")

gg.racf <- acf %>%
  left_join(primers) %>%
  select(-acf_npairs) %>%
  group_by(primer) %>%
  pivot_longer(starts_with("acf_"),
               names_to="type",
               values_to="value") %>%
  ungroup() %>%
 filter(type == "acf_acf", strand=="R") %>%
  mutate(new_order = factor(primer, levels = unique(primer[order(mean_mismatch)]))) %>%
#  mutate(primer = fct_reorder(primer, mean_mismatch)) %>%
ggplot(aes(x = distances, y=value)) +
  geom_line(alpha=1, colour="black") +
  geom_text(data=primers %>%
              filter(strand=="R") %>%
              mutate(new_order = factor(primer, levels = unique(primer[order(mean_mismatch)]))), aes(label = paste0("MM:", round(mean_mismatch,1)), x=2, y=-0.6), inherit.aes = FALSE, colour="red", hjust=0, check_overlap = TRUE) +
  base_theme +
  facet_wrap(~new_order) +
  labs(y = "Pearson correlation",
       x = "Phylogenetic distance",
       title = "Reverse primers")


gg.all_acf <- gg.facf + gg.racf

gg.all_acf

pdf(file="fig/supplementary/all_acf.pdf", width = 11, height = 8 , paper="a4r")
  plot(gg.all_acf)
try(dev.off(), silent=TRUE)
  
  
consentrait <- vroom::vroom("primer_evaluation/consentrait_mismatch.csv.gz") 

consentrait %>%
  left_join(primers %>% mutate(primer = name)) %>%
ggplot(aes(x = primer, y=mean_depth_pos_clades, size=traits_per_pos_clades )) +
  geom_point(alpha=0.2, colour="black") +
  facet_grid(strand~., drop = TRUE) +
  coord_flip()
  
```



## Get LCA Probabilities

```{r lca probs}
## Get LCA probs
library(furrr)
plan(multiprocess)

ranks = c("kingdom", 
    "phylum", "class", "order", "family", 
    "genus", "species")

lca_probs <- fs::dir_ls(path="primer_evaluation/amplicons/uclust_output/", glob = "*.txt.gz") %>%
  furrr::future_map(function(x){
  #purrr::map(function(x){
    print(x)
  df <- vroom::vroom(x, delim="\t", col_names = c("acc1", "acc2", "dist")) %>%
    dplyr::mutate(acc1 = acc1 %>%
                    str_remove(";$"),
                  acc2 = acc2 %>%
                    str_remove(";$"),
      dist = round(dist, 2),
                  ) 
  lca <- df %>%
    group_by(dist) %>%
    group_split() %>%
    purrr::map(function(y){
      print(unique(y$dist))
      logidf <- y %>% 
        tidyr::separate(acc1, into = c("Acc", paste0(ranks, "_1")), sep = ";") %>%
        tidyr::separate(acc2, into = c("Acc", paste0(ranks, "_2")), sep = ";") %>%
        transmute(
          kingdom = case_when(kingdom_1 == kingdom_2 ~ TRUE, TRUE ~ FALSE),
          phylum = case_when(phylum_1 == phylum_2 ~ TRUE, TRUE ~ FALSE),
          class = case_when(class_1 == class_2 ~ TRUE, TRUE ~ FALSE),
          order = case_when(order_1 == order_2 ~ TRUE, TRUE ~ FALSE),
          family = case_when(family_1 == family_2 ~ TRUE, TRUE ~ FALSE),
          genus = case_when(genus_1 == genus_2 ~ TRUE, TRUE ~ FALSE),
          species = case_when(species_1 == species_2 ~ TRUE, TRUE ~ FALSE),
          ) %>%
        dplyr::select(rev(ranks)) %>%
        as.data.frame()
        keepvec <- apply(logidf, 1, which.max)
        rows <- seq(as.data.frame(logidf)[, 1])
        selector <- matrix(ncol = 2, c(rows, keepvec))
        logidf[selector] <- "KEEP"
        logidf[!logidf == "KEEP"] <- 0
        logidf[logidf == "KEEP"] <- 1
        logidf <- logidf %>%
          mutate_all(as.numeric) %>%
          colSums()/length(rows) 
        out <-as_tibble(logidf, rownames="rank") %>%
          mutate(dist = unique(y$dist))
        return(out)
    }) %>%
  dplyr::bind_rows() %>% 
      dplyr::group_by(rank, dist) %>% 
      dplyr::summarise(prob = mean(value))
  
  return(lca)
  }) %>%
bind_rows(.id="source") %>%
mutate(source = str_remove(basename(source), ".txt.gz"))

#Write out lca probabilities
vroom::vroom_write(lca_probs, "primer_evaluation/lca_probs.csv")


# read in lca probabilities
lca <- vroom::vroom("primer_evaluation/lca_probs.csv") %>%
  dplyr::rename(name = source)

# Plot out
gg.lca <- lca %>%
  dplyr::filter(rank %in% c("species", "genus", "family", "order")) %>%
  mutate(rank = factor(rank, levels = c("species", "genus", "family", "order"))) %>%
  ggplot(aes(x=dist, y=prob, colour = name)) +
  geom_point() +
  base_theme +
  facet_wrap(~rank, ncol=1)

gg.lca

pdf(file="fig/lca_probabilities.pdf", width = 8, height = 11 , paper="a4")
  plot(gg.lca)
try(dev.off(), silent=TRUE)
 
``` 
 

# Off-target amplification

First identify all sequences that have homology to both forward and reverse primers, with the hit sequences placed so that they can actually form a PCR product. 
First perform a blast search for each primer individually against NT database (or can you do a kmer search with BBDUK?)
Get accession numbers, get taxonomy for accession numbers
then compare the lists for forward and reverse primers.
Any accession number that occurs in both lists needs to be investigated as a potential cross-reacting sequence
Get taxonomy for all cross reactign sequences, filter to those that are not insecta
Retrieve all sequences for cross reacting, make new database from those
Then do in-silico PCR with insect and count how many successfully amplify

```{r off target}
dir.create("primer_evaluation/off_target/individual", recursive = TRUE)
# Load primers
primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  dplyr::filter(!duplicated(name)) %>%
  mutate(seq = str_replace_all(seq, "I","N")) %>% 
  mutate(seq =case_when(
    strand=="F" ~ seq,
    strand=="R" ~ rc(seq) #Works without RC but RC seems faster
  )) 

# Disambiguate primers and write out individuals
seqs <- DECIPHER::Disambiguate(DNAStringSet(primers$seq))
names(seqs) <- primers$name

for (i in 1:length(seqs)){
  out <- unlist(seqs[i])
  #Sample 100 random permutations for degenerate primers
  out <- sample(out, 100, replace = TRUE) %>%
    unique()
  names(out) <- make.unique(names(out), sep="_")
  writeXStringSet(out, paste0("primer_evaluation/off_target/individual/",names(out[1]),".fa"))
}


dir.create("primer_evaluation/off_target/joined", recursive = TRUE)
# Get all possible primer combinations
combos <- expand_grid(primers %>% filter(strand=="F") %>% pull(seq),
                      primers %>% filter(strand=="R") %>% pull(seq)
                      ) %>%
  mutate_if(is.factor, as.character)%>%
  unique() %>%
  magrittr::set_colnames(c("Fseq", "Rseq")) %>%
  left_join(primers %>% filter(strand=="F") %>% rename_all(. %>% paste0("F",.)), by="Fseq") %>%
  left_join(primers %>% filter(strand=="R") %>% rename_all(. %>% paste0("R",.)), by="Rseq") %>%
  mutate(amplicon = Rstart - Fend) %>%
  filter( amplicon > 100) %>%
  mutate(synthetic = paste0(Fseq,"-", rc(Rseq) )) 

# Write out all combos - takes a while due to extremely high degeneracy!
for(i in 1:nrow(combos)){
  print(i)
  out <- DECIPHER::Disambiguate(DNAStringSet(combos$synthetic[i]))
  names(out) <- paste0(combos$Fname[i], "_",  combos$Rname[i])
  out <- unlist(out)
  # Pad with 20 N's
  out <- DNAStringSet(sapply(out, str_replace_all, pattern= "-", replacement="NNNNNNNNNNNNNNNNNNNN"))
  
  names(out) <- make.unique(names(out), sep="_")
  writeXStringSet(out, paste0("primer_evaluation/off_target/joined/", names(out[1]),".fa"))
}

# For the combos should i just take a random sample of 1000? as this is pretty ridiculous

```

# Off target chunked

Output all primer combos, fasta files in chunks of 100
Do as a BLAST array job
pull the taxid, and query name
get only unique taxid
save that as the results
Calculate off targets as proportion of insecta to total sequences amplified

Probably dont need to do it for all combos? just do for forward and reverse. Define it as a limitation 

```{r off target}
dir.create("primer_evaluation/off_target/individual_chunked", recursive = TRUE)
# Load primers
primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  dplyr::filter(!duplicated(name)) %>%
  mutate(seq = str_replace_all(seq, "I","N")) %>% 
  mutate(seq =case_when(
    strand=="F" ~ seq,
    strand=="R" ~ rc(seq) #Works without RC but RC seems faster
  )) 

# Disambiguate primers and write out individuals
seqs <- DECIPHER::Disambiguate(DNAStringSet(primers$seq))
names(seqs) <- primers$name

for (i in 1:length(seqs)){
  out <- unlist(seqs[i])
  names(out) <- make.unique(names(out), sep="_") 
  # Split into chunks of 100
  chunks <- split(out, ceiling(seq_along(out)/100))

  #write out chunks as seperate files
  for (c in 1:length(chunks)){
    filename <- paste0(names(seqs[i]),"_", names(chunks[c]))
    writeXStringSet(chunks[[c]],
                    paste0("primer_evaluation/off_target/individual_chunked/",filename,".fa.gz"),
                    compress = TRUE)
  }
}
```


See primerblast paper:

To evaluate specificity, artificial search sequences were generated by concatenating both primer sequences with a 20 base spacer. This ensures that each primer will be treated separately in the BLAST search and thus achieves the equivalent effect of performing a separate BLAST search for each primer. To create a database of potential non-target sequence ampliciations These artificial sequences as well as just the forward and reverse primers were searched against the local NCBI nr database using BLASTn

From primerserver code : https://github.com/billzt/PrimerServer/blob/master/script/_run_specificity_check.pl
blastn -task blastn-short -query $query_file -db $db_file -evalue 30000 "
                    ." -word_size 7 -perc_identity60 -dust no -ungapped -reward 1 -penalty -1 "
                    ." -max_hsps 500 -outfmt '6 qseqid qstart qend sseqid sstart send sstrand' "
                    ." -out $query_file.$db_name.out -num_threads $run_cpu";


Index jobs
```{bash generate job index}
#!/bin/bash
/usr/bin/ls -d $PWD/*.fa.gz | sort -u > sequence_index.txt
```

Submit array

njobs=$(cat sequence_index.txt | wc -l)

sbatch --array=1-930 primerblast.slurm

sbatch --array=1-4 primerblast.slurm

## BLAST
```{bash blast}
#!/bin/bash
#SBATCH --job-name=BLASTn       
#SBATCH --ntasks=1 
#SBATCH --cpus-per-task=4
#SBATCH --mem=20GB
#SBATCH --time=240:00:00
#SBATCH --mail-user=alexander.piper@agriculture.vic.gov.au
#SBATCH --mail-type=ALL
#SBATCH --account=pathogens
#SBATCH --export=none

#Check if job is launched as array
if [ -z "$SLURM_ARRAY_TASK_COUNT" ]; then 
  echo SLURM_ARRAY_TASK_COUNT unset; 
  echo You must launch this job as an array
  echo see https://slurm.schedmd.com/job_array.html
  echo for info on how to run arrays
  exit 1
fi
Index=sequence_index.txt

# Make sure that sequence index file is there before we do anything
if [[ ! -f "${Index}" ]]; then
  echo "Error sequence index file ${Index} does not exist"
  exit 1
fi

#Gather info on our samples
BlastDB=/group/blastdb/nt
FullSampleName=$(sed -n ${SLURM_ARRAY_TASK_ID}p ${Index})
SequencePath=$(dirname ${FullSampleName})
Sample=$(basename ${FullSampleName} .fa.gz)

# Double check that array index is valid
if [[ ! -f "${FullSampleName}" ]]; then
  echo "Error array index doesnt match up with index file"
  echo "Array index is  ${SLURM_ARRAY_TASK_ID}"
  exit 1
fi

# Goto tmp to do our processing
echo $TMPDIR
cd $TMPDIR
tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
cd $tmp_dir

#Copy data files, database and decompress all
cp ${FullSampleName} .
pigz -p8 -d ./*.gz
pwd
ls

#Load modules
module purge
module load BLAST+

###START###

echo ${BlastDB}
echo ${Sample}
date

blastn -task blastn-short \
-query ${Sample}.fa \
-db  ${BlastDB} \
-out ${Sample}.out \
-evalue 30000 \
-word_size 7 \
-perc_identity 60 \
-dust no \
-ungapped \
-reward 1 \
-penalty -1 \
-max_hsps 1 \
-max_target_seqs 1000000 \
-outfmt '6 qseqid qstart qend sseqid staxid sstart send sstrand' \
-num_threads 8

pigz ${Sample}.out

# Output useful job stats
/usr/local/bin/showJobStats.scr | gzip > ${Sample}-jobstats.gz

#Make a directory call ${Sample} and cp all output files into that directory
mkdir ${Sample}_output
cp ./*.gz ${Sample}_output

date

# put all output files back where we started
cp -r ${Sample}_output ${SLURM_SUBMIT_DIR}
```

## Extract fasta of all unique BLAST hits
```{bash}
#echo $() >  hits.txt
#for d in ./*_output/ ; do (cd "$d" && zcat *.out.gz | awk '{print $4}' | awk '{split($0,a,"|"); print a[2]}' | sort -u #>> ../hits.txt ); done
#cat hits.txt | sort -u > merged_hits.txt
#
##blastdbcmd -entry_batch merged_hits.txt -db /group/blastdb/nt -out merged_hits.fa 

```


## Extract taxid of all unique BLAST hits

This loops through all out files in the output subfolders and merges the unique tax_ids into hits

The awk call splits the primer name to remove the chunk ID (ie primer_1 > primer 1 ), then prints just the primer and tax_ids, then call unique
```{bash}
echo $() >  hits.txt
for d in ./*_output/ ; do (cd "$d" && zcat *.out.gz | awk '{split($1,a,"_"); print a[1], $5}'| sort -u >> ../hits.txt ); done
cat hits.txt | sort -u > merged_hits.txt
pigz merged_hits.txt
rm hits.txt

```


## Process hits

```{r process blast taxonomy}
# Load primers
primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  mutate(seq = str_replace_all(seq, "I","N")) %>% 
  select(-score, -issues) %>%
  distinct()


hits <- vroom::vroom("primer_evaluation/merged_hits.txt.gz", col_names=c("primer", "tax_id"))

db <- taxreturn::get_ncbi_lineage()

off_target <- hits %>% 
  left_join(db, by="tax_id") %>%
  mutate(is_arthropod = case_when(
    phylum=="Arthropoda" ~ TRUE,
    !phylum=="Arthropoda" ~ FALSE
  ), is_insect = case_when(
    class=="Insecta" ~ TRUE,
    !class=="Insecta" ~ FALSE
  )) %>%
  group_by(primer)%>%
  summarise(freq_arthropod=(sum(is_arthropod, na.rm = TRUE)/n()),
            freq_insect=(sum(is_insect, na.rm = TRUE)/n()),
            n=n()
            ) %>%
  arrange(freq_arthropod) %>%
  mutate(name = primer) %>%
  left_join(primers)

#Relationshup with degeneracy
off_target %>%
  pivot_longer(starts_with("freq"),
               names_to = "type",
               values_to = "freq") %>%
  mutate(primer = as.factor(primer),
         primer = fct_reorder(primer, freq, .desc=FALSE)) %>%
  ggplot(aes(x=primer, y=freq, fill=degeneracy)) +
  geom_col() +
  facet_grid(~type) +
  base_theme +
  coord_flip()+
  theme(legend.position = "bottom") +
  scale_fill_gradient(low = "darkslateblue" , high ="firebrick", 
                      na.value = "grey",limits=c(0, 1000), oob = scales::squish)+
  labs(title = "Fill = Degeneracy",
       fill = "Primer Degeneracy")


# See if its capturing primer length:
off_target %>%
  pivot_longer(starts_with("freq"),
               names_to = "type",
               values_to = "freq") %>%
  mutate(primer = as.factor(primer),
         primer = fct_reorder(primer, freq, .desc=FALSE)) %>%
  ggplot(aes(x=primer, y=freq, fill=length)) +
  geom_col() +
  facet_grid(~type) +
  base_theme +
  coord_flip()+
  theme(legend.position = "bottom") +
  scale_fill_gradient(low = "darkslateblue" , high ="firebrick", 
                      na.value = "grey")+
  labs(title = "Fill = Primer Length",
       Fill = "Primer length")

# Why are some missing?
```

# PrimerTree

Note: Detailed information about installing and running PrimerTree can be found at https://github.com/jimhester/primerTree

Could use a slurm array to submit each seperately with all combinatons. 
Also worth having a function to count degeneracy for the constraints section
```{r off target}
primers <- read_csv("primer_evaluation/primer_candidates.csv")
library(primerTree)


forward <- "GGDRCWGGWTGAACWGTWTAYCCNCC"
rev <- "TATDGTRATDGCHCCNGC"

test <- search_primer_pair(
  forward,
  rev,
  api_key ="1c0a0c4afa28448650a1450662a22c68f208",
  num_permutations = 20
)
ranks = c("kingdom", "phylum", "class", 
    "order", "family", "genus", "species")

lineage <- test3[["taxonomy"]] %>%
  select(all_of(ranks))%>% 
  tidyr::unite(col = pathString, 
  !!ranks, sep = "/") %>%
  dplyr::mutate(pathString = paste0("Root/", pathString)) %>%
  data.tree::as.Node(.)

tree <- ape::read.tree(textConnection(data.tree::ToNewick(lineage, heightAttribute = NULL)))

library(ggtree)

ggtree(tree)


dir.create("PrimerTree")
#for (i in 1:nrow(dat.I)) {
  assign(paste("PT", dat.I$Name[i], sep = "."), search_primer_pair(name = dat.I$Name[i], dat.I$F.seq[i], dat.I$R.seq[i], num_permutations = 50, num_aligns = 1000))
  saveRDS(paste("PT", dat.I$Name[i], sep = "."),paste0("PrimerTree/PT.",dat.I$Name[i],".rds"))
}
#, clustal_options = c(exec='clustal-omega-1.2.2-win64/clustalo.exe')

# 3.2. - Inspect the sequence length distribution for each primer pair and remove any sequence records with a length deviating from the
#        majority of the sequences.

#Below code requires clustal files in R install directory

seq_lengths(`PT.AgPestF1-AgPestR1a`) # No obvious outliers
`PT.AgPestF1-AgPestR1a` <- filter_seqs(`PT.AgPestF1-AgPestR1a`, min_length = 200)

seq_lengths(`PT.AgPestF2-AgPestR2`) # No obvious outliers
`PT.AgPestF2-AgPestR2` <- filter_seqs(`PT.AgPestF2-AgPestR2`, min_length = 200)

seq_lengths(`PT.fwhF2-fwhR2n`) # No obvious outliers
`PT.fwhF2-fwhR2n` <- filter_seqs(`PT.fwhF2-fwhR2n`, min_length = 200)

seq_lengths(`PT.SauronS878-BR1`) # No obvious outliers
`PT.SauronS878-BR1` <- filter_seqs(`PT.SauronS878-BR1`, min_length = 200)

#Plot trees
t1 <- plot(`PT.AgPestF1-AgPestR1a`, ranks='class', main='PT.AgPestF1-AgPestR1a', rotate=45, size=1)
t2 <- plot(`PT.AgPestF2-AgPestR2`, ranks='class', main='PT.AgPestF2-AgPestR2', rotate=45, size=1)
t3 <- plot(`PT.fwhF2-fwhR2n`, ranks='class', main='PT.fwhF2-fwhR2n', rotate=45, size=1)
t4 <- plot(`PT.SauronS878-BR1`, ranks='class', main='PT.SauronS878-BR1', rotate=45, size=1)

Fig3 <- t1+t2+t3+t4
#on this plot we can see: 
#Off target amplifications
#Longer branch length = higher resolution


# 3.3. - Evaluate the taxonomic coverage and the specificity of the primers within the Actinopterygii class (i.e. Actinopteri class based
#        on the NCBI nomenclature). Also evaluate the taxonomic resolution of the primers at the genus level and correct for length of the
#        barcode to allow for comparisons between primers. Add additional columns to the input file for all calculated statistics.

dat.I$PT.Specificity <- rep("", nrow(dat.I))
dat.I$PT.PWDistance <- rep("", nrow(dat.I))
dat.I$PT.Length <- rep("", nrow(dat.I))
dat.I$PT.Resolution <- rep("", nrow(dat.I))
dat.I$PT.Order <- rep("", nrow(dat.I))
dat.I$PT.Family <- rep("", nrow(dat.I))
dat.I$PT.Genus <- rep("", nrow(dat.I))

for (i in 1:nrow(dat.I)) {
  tmp1 <- paste("PT", dat.I$Name[i], sep = ".")
  TAXID.All <- length(unique(as.data.frame(get(tmp1)$taxonomy)$taxId))
  TAXID.Act <- length(unique(subset(as.data.frame(get(tmp1)$taxonomy), subset = class == "Insecta")$taxId))
  dat.I$PT.Specificity[i] <- round((TAXID.Act / TAXID.All) * 100, digits = 2)
  dat.I$PT.PWDistance[i] <- as.numeric(calc_rank_dist_ave(get(tmp1), ranks = c("genus")))
  dat.I$PT.Length[i] <- as.integer(mean(get(tmp1)$BLAST_result$product_length))
  dat.I$PT.Resolution[i] <- as.numeric(dat.I$PT.PWDistance[i]) / as.numeric(dat.I$PT.Length[i])
  dat.I$PT.Order[i] <- length(unique(subset(as.data.frame(get(tmp1)$taxonomy), subset = class == "Insecta")$order))
  dat.I$PT.Family[i] <- length(unique(subset(as.data.frame(get(tmp1)$taxonomy), subset = class == "Insecta")$family))
  dat.I$PT.Genus[i] <- length(unique(subset(as.data.frame(get(tmp1)$taxonomy), subset = class == "Insecta")$genus))
}

#   B. Primer specificity (i.e. the percentage of unique Actinopterygii species out of the total number of unique species recovered)

gg.specificity <- ggplot(dat.I, aes(x = factor(Name, levels = Name), y = as.numeric(PT.Specificity))) +
  geom_bar(stat = "identity", fill = "gray50") +
  geom_hline(aes(yintercept = 90), linetype = "dashed", colour = "red3") +
  coord_cartesian(ylim = c(30, 100)) +
  ggtitle("B") +
  ylab("% of unique Actinopterygii species") +
  theme_classic() +
  theme(
    plot.title = element_text(size = 8, colour = "black", face = "bold"),
    axis.title.x = element_blank(),
    axis.title.y = element_text(size = 7, colour = "black"),
    axis.text.x = element_text(size = 7, colour = "black", angle = 90, hjust = 1, vjust = 0.5),
    axis.text.y = element_text(size = 7, colour = "black"),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_line(size = 0.25, colour = "black"),
    axis.ticks.length = unit(0.1, "cm")
  )
gg.specificity

#   C. Taxonomic coverage (i.e. no. of Actinopterygii orders for which sequences were obtained)

gg.coverage <- ggplot(dat.I, aes(x = factor(Name, levels = Name), y = as.numeric(PT.Order))) +
  geom_bar(stat = "identity", fill = "gray50") +
  geom_hline(aes(yintercept = 30), linetype = "dashed", colour = "red3") +
  coord_cartesian(ylim = c(0, 40)) +
  ggtitle("C") +
  ylab("No. of Actinopterygii orders") +
  theme_classic() +
  theme(
    plot.title = element_text(size = 8, colour = "black", face = "bold"),
    axis.title.x = element_blank(),
    axis.title.y = element_text(size = 7, colour = "black"),
    axis.text.x = element_text(size = 7, colour = "black", angle = 90, hjust = 1, vjust = 0.5),
    axis.text.y = element_text(size = 7, colour = "black"),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_line(size = 0.25, colour = "black"),
    axis.ticks.length = unit(0.1, "cm")
  )
gg.coverage

```


```{r sessioninfo}
sessionInfo(package = NULL)
```
